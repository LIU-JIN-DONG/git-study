// Audio Analyzer Class for Real-time Audio Detection
// ä¼˜åŒ–ç‰ˆæœ¬ï¼šæ›´æ•æ„Ÿçš„éŸ³é¢‘æ£€æµ‹ï¼ŒåŒ…å«éŸ³é¢‘ä¿æŒæœºåˆ¶
export class AudioAnalyzer {
    constructor() {
        this.audioContext = null;
        this.analyserNode = null;
        this.mediaStreamSource = null;
        this.dataArray = null;
        this.isAnalyzing = false;
        this.animationId = null;
        
        // é…ç½®å‚æ•°
        this.fftSize = 256;
        this.smoothingTimeConstant = 0.8;
        this.silenceThreshold = 2;          // é™éŸ³é˜ˆå€¼ (é™ä½åˆ°2ï¼Œæ›´æ•æ„Ÿ)
        this.audioThreshold = 5;            // æœ‰éŸ³é¢‘é˜ˆå€¼ (é™ä½åˆ°5ï¼Œæ›´å®¹æ˜“è§¦å‘)
        this.debounceCount = 0;             // é˜²æŠ–åŠ¨è®¡æ•°
        this.debounceLimit = 2;             // é˜²æŠ–åŠ¨é™åˆ¶ (å‡å°‘åˆ°2æ¬¡ï¼Œæ›´å¿«å“åº”)
        this.audioHoldTime = 0;             // éŸ³é¢‘ä¿æŒæ—¶é—´è®¡æ•°
        this.audioHoldLimit = 8;            // éŸ³é¢‘ä¿æŒé™åˆ¶ (æ£€æµ‹åˆ°éŸ³é¢‘åä¿æŒ8æ¬¡å¾ªç¯)
        
        // å›è°ƒå‡½æ•°
        this.onAudioDetected = null;
        this.onSilenceDetected = null;
        this.currentState = 'silence';      // 'silence' | 'audio'
    }
    
    // åˆå§‹åŒ–éŸ³é¢‘åˆ†æå™¨
    async initialize(mediaStream) {
        try {
            // åˆ›å»ºéŸ³é¢‘ä¸Šä¸‹æ–‡
            this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
            
            // åˆ›å»ºåˆ†æå™¨èŠ‚ç‚¹
            this.analyserNode = this.audioContext.createAnalyser();
            this.analyserNode.fftSize = this.fftSize;
            this.analyserNode.smoothingTimeConstant = this.smoothingTimeConstant;
            
            // åˆ›å»ºåª’ä½“æµæº
            this.mediaStreamSource = this.audioContext.createMediaStreamSource(mediaStream);
            
            // è¿æ¥èŠ‚ç‚¹
            this.mediaStreamSource.connect(this.analyserNode);
            
            // åˆ›å»ºæ•°æ®æ•°ç»„
            const bufferLength = this.analyserNode.frequencyBinCount;
            this.dataArray = new Uint8Array(bufferLength);
            
            console.log('âœ… Audio analyzer initialized successfully');
            return true;
        } catch (error) {
            console.error('âŒ Failed to initialize audio analyzer:', error);
            return false;
        }
    }
    
    // å¼€å§‹åˆ†æ
    startAnalysis() {
        if (!this.analyserNode || this.isAnalyzing) return;
        
        this.isAnalyzing = true;
        this.currentState = 'silence';
        this.debounceCount = 0;
        this.analyzeAudio();
        
        console.log('ğŸµ Audio analysis started');
    }
    
    // åœæ­¢åˆ†æ
    stopAnalysis() {
        this.isAnalyzing = false;
        
        if (this.animationId) {
            cancelAnimationFrame(this.animationId);
            this.animationId = null;
        }
        
        console.log('ğŸ›‘ Audio analysis stopped');
    }
    
    // æ¸…ç†èµ„æº
    cleanup() {
        this.stopAnalysis();
        
        if (this.mediaStreamSource) {
            this.mediaStreamSource.disconnect();
            this.mediaStreamSource = null;
        }
        
        if (this.audioContext) {
            this.audioContext.close();
            this.audioContext = null;
        }
        
        this.analyserNode = null;
        this.dataArray = null;
        
        console.log('ğŸ§¹ Audio analyzer cleaned up');
    }
    
    // åˆ†æéŸ³é¢‘æ•°æ®
    analyzeAudio() {
        if (!this.isAnalyzing || !this.analyserNode) return;
        
        // è·å–éŸ³é¢‘æ•°æ®
        this.analyserNode.getByteTimeDomainData(this.dataArray);
        
        // è®¡ç®—éŸ³é¢‘å¼ºåº¦
        const audioLevel = this.calculateAudioLevel();
        
        // çŠ¶æ€åˆ¤æ–­å’Œé˜²æŠ–åŠ¨
        this.processAudioLevel(audioLevel);
        
        // ç»§ç»­åˆ†æ
        this.animationId = requestAnimationFrame(() => this.analyzeAudio());
    }
    
    // è®¡ç®—éŸ³é¢‘å¼ºåº¦
    calculateAudioLevel() {
        let sum = 0;
        for (let i = 0; i < this.dataArray.length; i++) {
            const sample = (this.dataArray[i] - 128) / 128;
            sum += sample * sample;
        }
        return Math.sqrt(sum / this.dataArray.length) * 100;
    }
    
    // å¤„ç†éŸ³é¢‘å¼ºåº¦å¹¶è¿›è¡Œé˜²æŠ–åŠ¨
    processAudioLevel(audioLevel) {
        const hasAudio = audioLevel > this.audioThreshold;
        
        // å¦‚æœæ£€æµ‹åˆ°éŸ³é¢‘ï¼Œé‡ç½®ä¿æŒæ—¶é—´
        if (hasAudio) {
            this.audioHoldTime = this.audioHoldLimit;
        }
        
        // ç¡®å®šæ–°çŠ¶æ€ï¼šæœ‰éŸ³é¢‘æˆ–è€…åœ¨ä¿æŒæœŸå†…éƒ½ç®—ä½œaudioçŠ¶æ€
        const newState = hasAudio || this.audioHoldTime > 0 ? 'audio' : 'silence';
        
        // å‡å°‘ä¿æŒæ—¶é—´è®¡æ•°
        if (this.audioHoldTime > 0) {
            this.audioHoldTime--;
        }
        
        if (newState !== this.currentState) {
            this.debounceCount++;
            
            if (this.debounceCount >= this.debounceLimit) {
                const previousState = this.currentState;
                this.currentState = newState;
                this.debounceCount = 0;
                
                // æ·»åŠ æ›´è¯¦ç»†çš„æ—¥å¿—
                console.log(`ğŸ”„ Audio state changed: ${previousState} â†’ ${newState} (level: ${audioLevel.toFixed(2)}, hold: ${this.audioHoldTime})`);
                
                // è§¦å‘å›è°ƒ
                if (newState === 'audio' && this.onAudioDetected) {
                    this.onAudioDetected(audioLevel);
                } else if (newState === 'silence' && this.onSilenceDetected) {
                    this.onSilenceDetected(audioLevel);
                }
            }
        } else {
            this.debounceCount = 0;
        }
    }
    
    // è®¾ç½®å›è°ƒå‡½æ•°
    setCallbacks(onAudioDetected, onSilenceDetected) {
        this.onAudioDetected = onAudioDetected;
        this.onSilenceDetected = onSilenceDetected;
    }
    
    // è·å–å½“å‰çŠ¶æ€
    getCurrentState() {
        return this.currentState;
    }
} 