<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <title>Turn-based Translation Demo (Overlay for STT)</title>
  <!-- Font Awesome (for microphone icon) -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" />
  <!-- Azure Speech SDK (STT) -->
  <script src="https://aka.ms/csspeech/jsbrowserpackageraw"></script>
  <!-- 添加全局变量定义 -->
  <script>
    // 超时和处理状态控制
    const MAX_PROCESSING_TIME = 20000; // 最大处理时间20秒
    let processingStartTime = 0;       // 记录处理开始时间
    let processingTimeoutId = null;    // 添加超时ID变量
    // 添加全局变量定义
    let isNewRecordingSession = false; // 标记是否是新的录音会话
    let recordingSessionId = null;     // 当前录音会话ID
  </script>
  <style>
    * {
      box-sizing: border-box;
    }

    body {
      margin: 0;
      padding: 0;
      font-family: "Microsoft YaHei", "微软雅黑", -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol", "Noto Color Emoji";
      background: #f0f0f0;
    }

    /* 顶部标题 */
    header {
      background: #4c6ef5;
      color: #fff;
      padding: 15px;
      text-align: center;
      font-size: 1.2rem;
      font-weight: bold;
    }

    /* 主容器 */
    .container {
      width: 95%;
      margin: 20px auto;
      background: #fff;
      border-radius: 8px;
      box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
      padding: 20px;
    }

    /* 语言设置与状态区域 */
    .settings-row {
      display: flex;
      flex-wrap: wrap;
      align-items: center;
      gap: 10px;
      margin-bottom: 20px;
    }

    .settings-row label {
      font-size: 0.9rem;
      color: #333;
    }

    .settings-row select {
      margin: 0 5px;
      padding: 4px 8px;
      font-size: 0.9rem;
    }

    .settings-row button {
      padding: 6px 12px;
      font-size: 0.9rem;
      cursor: pointer;
      background-color: #4c6ef5;
      color: #fff;
      border: none;
      border-radius: 4px;
      transition: background-color 0.2s ease;
    }

    .settings-row button:hover {
      background-color: #3b5ce8;
    }

    /* 行内状态 (ML / TL) */
    .status-inline {
      font-size: 0.9rem;
      color: #444;
      margin-left: 10px;
    }

    .status-inline span {
      font-weight: bold;
      color: #333;
    }

    /* 文本框并排布局 */
    .text-columns {
      display: flex;
      gap: 26px;
      margin-bottom: 20px;
    }

    .column {
      flex: 1;
      display: flex;
      flex-direction: column;
      gap: 10px;
    }

    /* 文本域高度、字体 */
    .column textarea {
      width: 100%;
      flex: 1;
      min-height: 800px;
      padding: 8px;
      font-size: 1.4rem;
      line-height: 1.2;
      font-family: "Microsoft YaHei", "微软雅黑", Consolas, "Courier New", monospace, -apple-system, BlinkMacSystemFont, "Segoe UI", Arial, sans-serif;
      border: 1px solid #ccc;
      border-radius: 4px;
      resize: vertical;
    }

    /* 按钮区：发送、录音 */
    .btn-row {
      display: flex;
      gap: 10px;
      flex-wrap: wrap;
    }

    .btn-send,
    .btn-record {
      padding: 8px 16px;
      font-size: 1rem;
      cursor: pointer;
      border-radius: 4px;
      border: none;
      transition: background-color 0.2s ease;
      color: #fff;
    }

    .btn-send {
      background-color: #4c6ef5;
    }

    .btn-send:hover {
      background-color: #3b5ce8;
    }

    .btn-record {
      background-color: #adb5bd;
      display: flex;
      align-items: center;
      gap: 6px;
      min-width: 120px;
      /* 给按钮留些空间显示时长 */
    }

    .btn-record:hover {
      background-color: #868e96;
    }

    /* 历史记录区域 + 折叠展开 */
    .log-header {
      display: flex;
      align-items: center;
      justify-content: space-between;
      margin-bottom: 8px;
    }

    .log-title {
      font-size: 1rem;
      font-weight: bold;
      color: #333;
      border-left: 4px solid #4c6ef5;
      padding-left: 8px;
    }

    .log-toggle-btn {
      padding: 6px 12px;
      border: none;
      border-radius: 4px;
      background-color: #adb5bd;
      color: #fff;
      cursor: pointer;
      transition: background-color 0.2s ease;
      font-size: 0.9rem;
    }

    .log-toggle-btn:hover {
      background-color: #868e96;
    }

    .log-container {
      margin-top: 10px;
      border-top: 1px solid #ccc;
      padding-top: 10px;
    }

    .log-collapsed {
      display: none;
    }

    /* 日志内容 */
    .log-item {
      padding: 8px 0;
      border-bottom: 1px dashed #ddd;
      font-size: 0.95rem;
      line-height: 1.3;
      white-space: pre-wrap;
    }

    .log-item p {
      margin: 4px 0;
    }

    .log-item p:first-child {
      font-weight: bold;
      color: #333;
    }

    /* 播放器控制按钮样式 */
    #playPauseBtn {
      background-color: #4c6ef5;
      color: #fff;
      padding: 8px 16px;
      border: none;
      border-radius: 4px;
      cursor: pointer;
      transition: background-color 0.2s ease;
      min-width: 80px;
      font-size: 1rem;
    }

    #playPauseBtn:hover {
      background-color: #3b5ce8;
    }

    /* 播放器其他控件样式调整 */
    #audioPlayer {
      margin-top: 20px;
    }

    #audioPlayer>div {
      display: flex;
      align-items: center;
      gap: 10px;
    }

    #speedRange {
      width: 100px;
    }

    #progressRange {
      flex: 1;
    }

    /* ======= 新增的遮罩层(Overlay)样式 ======= */
    .overlay {
      position: fixed;
      top: 0;
      left: 0;
      right: 0;
      bottom: 0;
      background: rgba(0, 0, 0, 0.5);
      z-index: 9999;
      display: none;
      /* 默认隐藏 */
      align-items: center;
      justify-content: center;
    }

    .overlay.show {
      display: flex;
      /* 显示时采用flex居中 */
    }

    .overlay-content {
      background: #fff;
      padding: 20px;
      width: 90%;
      max-width: 600px;
      border-radius: 8px;
      box-shadow: 0 2px 8px rgba(0, 0, 0, 0.3);
    }

    .overlay-textarea {
      width: 100%;
      min-height: 200px;
      padding: 10px;
      font-size: 1.2rem;
      border: 1px solid #ccc;
      border-radius: 4px;
      resize: vertical;
    }

    #overlayStopBtn {
      background-color: #4c6ef5;
      color: #fff;
      border: none;
      border-radius: 4px;
      padding: 8px 16px;
      font-size: 1rem;
      cursor: pointer;
      margin-top: 10px;
    }

    #overlayStopBtn:hover {
      background-color: #3b5ce8;
    }

    /* 新增蓝牙麦克风相关样式 */
    .btn-record.connected {
      background-color: #4c6ef5;
    }

    .btn-record.connecting {
      background-color: #ffd43b;
    }

    .btn-record.waiting {
      animation: blinkYellow 1s infinite;
    }

    .btn-record.recording {
      animation: blinkRed 1s infinite;
    }

    @keyframes blinkYellow {
      0% {
        background-color: #4c6ef5;
      }

      50% {
        background-color: #748ffc;
      }

      100% {
        background-color: #4c6ef5;
      }
    }

    @keyframes blinkRed {
      0% {
        background-color: #fa5252;
      }

      50% {
        background-color: #ff8787;
      }

      100% {
        background-color: #fa5252;
      }
    }

    .audio-controls {
      display: flex;
      gap: 10px;
      margin-top: 8px;
    }

    .audio-btn {
      background-color: #4c6ef5;
      color: #fff;
      border: none;
      border-radius: 4px;
      padding: 4px 8px;
      font-size: 0.85rem;
      cursor: pointer;
      transition: background-color 0.2s;
    }

    .audio-btn:hover {
      background-color: #3b5ce8;
    }

    @media (max-width: 768px) {

      .text-columns,
      #audioPlayer>div {
        flex-direction: column;
      }

      .column {
        width: 100%;
      }

      .column textarea {
        min-height: 300px;
      }
    }
  </style>
</head>

<body>
  <header>
    Turn-based Translation Demo (Overlay for STT)
  </header>

  <div class="container">
    <!-- 语言设置与状态 -->
    <div class="settings-row">
      <label>
        Main Language (ML):
        <select id="manualMainLang">
          <option value="">(none)</option>
          <option value="zh">Chinese (zh)</option>
          <option value="en">English (en)</option>
          <option value="fr">French (fr)</option>
          <option value="es">Spanish (es)</option>
          <option value="de">German (de)</option>
          <option value="it">Italian (it)</option>
          <option value="ja">Japanese (ja)</option>
          <option value="ko">Korean (ko)</option>
          <option value="ru">Russian (ru)</option>
          <option value="pt">Portuguese (pt)</option>
          <option value="ar">Arabic (ar)</option>
          <option value="hi">Hindi (hi)</option>
          <option value="tr">Turkish (tr)</option>
          <option value="nl">Dutch (nl)</option>
          <option value="pl">Polish (pl)</option>
        </select>
      </label>
      <label>
        Target Language (TL):
        <select id="manualTargetLang">
          <option value="">(none)</option>
          <option value="zh">Chinese (zh)</option>
          <option value="en">English (en)</option>
          <option value="fr">French (fr)</option>
          <option value="es">Spanish (es)</option>
          <option value="de">German (de)</option>
          <option value="it">Italian (it)</option>
          <option value="ja">Japanese (ja)</option>
          <option value="ko">Korean (ko)</option>
          <option value="ru">Russian (ru)</option>
          <option value="pt">Portuguese (pt)</option>
          <option value="ar">Arabic (ar)</option>
          <option value="hi">Hindi (hi)</option>
          <option value="tr">Turkish (tr)</option>
          <option value="nl">Dutch (nl)</option>
          <option value="pl">Polish (pl)</option>
        </select>
      </label>
      <button id="applyManualBtn">Apply Settings</button>

      <!-- 显示ML/TL状态 -->
      <div class="status-inline">
        ML: <span id="spanMainLang">unset</span> |
        TL: <span id="spanTargetLang">unset</span>
      </div>
    </div>

    <!-- 左右文本框 -->
    <div class="text-columns">
      <!-- 左侧：输入框 + 发送/录音按钮 -->
      <div class="column">
        <label for="inputText">Input Text</label>
        <textarea id="inputText" placeholder="Type or paste text here... (Double-click to clear)"></textarea>
        <div class="btn-row">
          <button id="sendBtn" class="btn-send">Send Text</button>
          <button id="recordBtn" class="btn-record">
            <i class="fas fa-microphone"></i> Record
          </button>
          <button id="gmicMicBtn" class="btn-record">
            <i class="fas fa-bluetooth"></i> GMIC-MIC01
          </button>
          <button id="gmicMicBtn2" class="btn-record">
            <i class="fas fa-bluetooth"></i> GMIC-MIC02
          </button>
        </div>
      </div>

      <!-- 右侧：翻译结果(只读) -->
      <div class="column">
        <label for="outputText">Translated Text</label>
        <textarea id="outputText" readonly placeholder="Translation result here..."></textarea>
      </div>
    </div>

    <!-- 播放器区域 -->
    <div id="audioPlayer" style="margin-top: 20px;">
      <audio id="ttsAudio" preload="auto" style="display:none;"></audio>
      <div>
        <button id="playPauseBtn">Play</button>
        <span><label for="speedRange">Speed:</label>
          <input type="range" id="speedRange" min="0.5" max="2" step="0.1" value="1">
          <span id="speedValue">1.0x</span></span>
        <span><input type="range" id="progressRange" min="0" max="100" value="0">
          <span id="currentTime">00:00</span> / <span id="duration">00:00</span></span>
      </div>
    </div>

    <!-- 翻译历史日志(折叠) -->
    <div class="log-container" id="logContainerParent">
      <div class="log-header">
        <div class="log-title">Translation History (Newest First)</div>
        <button class="log-toggle-btn" id="toggleLogBtn">Show Log</button>
      </div>
      <div id="logContainer" class="log-collapsed"></div>
    </div>
  </div>

  <!-- ======= 录音期间的遮罩层 ======= -->
  <div id="sttOverlay" class="overlay">
    <div class="overlay-content">
      <h3>Recording ...</h3>
      <!-- 实时转写文字 显示在这里 -->
      <textarea id="overlayTranscription" class="overlay-textarea" readonly></textarea>

      <button id="overlayStopBtn">Stop</button>
    </div>
  </div>

  <script>
    /*************************************************************
     * 1. 配置信息：请在此填写你的Azure和OpenAI密钥及endpoint
     *************************************************************/
    // ============= Replace with your own keys (NOT safe for production) ============

    // OpenAI (Whisper + GPT)
    const OPENAI_API_KEY = "xxxx";
    const OPENAI_WHISPER_URL = "https://api.openai.com/v1/audio/transcriptions";
    const OPENAI_API_URL = "https://api.openai.com/v1/chat/completions";
    const OPENAI_TTS_URL = "https://api.openai.com/v1/audio/speech"; // OpenAI TTS API

    // Azure TTS
    const AZURE_TTS_KEY = "xxxx";
    const AZURE_TTS_ENDPOINT = "https://westus.tts.speech.microsoft.com/cognitiveservices/v1";

    // Azure STT (语音转写)
    //   需要 Azure Speech Resource: subscription key, region
    const AZURE_SPEECH_KEY = AZURE_TTS_KEY;  // Use the same key as TTS
    const AZURE_SPEECH_REGION = "westus";     // Use the same region as TTS

    // 添加OpenAI GPT-4o mini Transcribe API配置
    const OPENAI_STREAM_TRANSCRIBE_URL = "https://api.openai.com/v1/audio/transcriptions";
    // 使用gpt-4o-mini-transcribe或whisper-1模型以获得更好的转录能力
    const OPENAI_STREAM_TRANSCRIBE_MODEL = "gpt-4o-mini-transcribe";
    const MIN_PCM_DATA_SIZE_FOR_TRANSCRIPTION = 16000; // 降低转写所需的最小数据量，每次约0.5秒
    let lastTranscribeTime = 0;
    const TRANSCRIBE_INTERVAL = 1000; // 降低转写间隔到1秒，使转写更加频繁
    let streamTranscriptionInProgress = false;
    let transcribedText = "";
    let temporaryBuffer = [];
    let streamTranscribeTimeoutId = null;
    // 添加语言自动检测标志
    let detectedLanguage = null;

    /*************************************************************
     * 2. 全局变量 & 工具函数
     *************************************************************/
    let mainLanguage = null;
    let targetLanguage = null;
    let userHasManualMain = false;
    let userHasManualTarget = false;

    // 用于只弹一次权限请求
    let micStream = null;      // 记录用户麦克风stream
    let recognizer = null;     // Azure SpeechRecognizer实例
    let mediaRecorder = null;  // Browser MediaRecorder
    let recordChunks = [];
    let isRecording = false;
    let recordStartTime = null;
    let recordTimer = null;

    // DOM缓存
    const recordBtn = document.getElementById("recordBtn");
    const inputText = document.getElementById("inputText");
    const translatedText = document.getElementById("outputText");
    const overlay = document.getElementById("sttOverlay");
    const overlayTranscription = document.getElementById("overlayTranscription");
    const overlayStopBtn = document.getElementById("overlayStopBtn");

    // BLE UUID 常量定义
    const voiceServiceUUID1 = '0000181c-0000-1000-8000-00805f9b34fb';  // Voice service (主服务)
    const voiceServiceUUID2 = '0000181c-0000-1000-8000-00805f9b34fb';  // Same as UUID1 (备用)
    const buttonCharacteristicUUID = '00002b7a-0000-1000-8000-00805f9b34fb'; // App control characteristic
    const voiceDataCharacteristicUUID = '00002bcd-0000-1000-8000-00805f9b34fb'; // Voice data characteristic

    // 蓝牙麦克风相关变量
    let bluetoothDevices = [null, null]; // 存储两个蓝牙设备
    let gattServers = [null, null];
    let voiceServices = [null, null];
    let voiceDataCharacteristics = [null, null];
    let isBluetoothRecording = false;
    let isProcessingData = false;
    let fullPcmDataArray = [];
    let lastDataReceivedTime = Date.now();
    const dataTimeout = 500; // ms
    let connectTrys = 0;
    let voiceServiceUUID = voiceServiceUUID1;
    let bleRecognizer = null;  // Azure recognizer for BLE mic
    let accumulatedText = "";  // 累积的识别文本
    let currentPartialText = ""; // 当前正在识别的临时文本
    let checkDataTimeoutInterval = null; // 用于检查数据接收超时的定时器
    let azureConnectionFailed = false; // 标记Azure连接是否失败
    let audioRetryCount = 0; // 用于记录音频初始化重试次数
    const gmicMicBtn = document.getElementById("gmicMicBtn");
    const gmicMicBtn2 = document.getElementById("gmicMicBtn2");
    // 当前活动麦克风索引
    let activeMicIndex = -1;
    // 录音时长计时器
    let bleRecordStartTime = null; // 蓝牙录音开始时间
    let bleRecordTimer = null;     // 蓝牙录音计时器
    // 按键信号
    let lastButtonSignal = -1; // 记录上一次按键信号，初始值为-1表示未知
    // 添加初始化状态标志，防止重复初始化
    let isRecognizerInitializing = false; // 标记识别器是否正在初始化中
    // 处理时间记录 - 不再重新声明，使用全局变量
    // processingStartTime 在顶部脚本已声明

    // 历史录音和TTS存储
    let audioHistory = []; // 存储历史录音和TTS的数组
    let currentAudioBlob = null; // 当前录音的Blob
    let currentTTSBlob = null; // 当前TTS的Blob
    let sessionTranslationTarget = null; // 当前会话的翻译目标语言
    let recognizerInitComplete = false; // 标记识别器是否初始化完成

    // 保存用户设置的播放速度
    let savedPlaybackSpeed = 1.0; // 默认速度为1.0

    // 添加数据发送计数器变量（移至全局作用域）
    let dataSendCounter = 0;
    let totalDataSent = 0;

    // 添加识别器初始化超时变量
    let initRecognizerTimeout = null;
    const MAX_RECOGNIZER_INIT_TIME = 5000; // 最大等待识别器初始化的时间(5秒)

    // ADPCM 解码表 - 从index.html复制过来
    const idxtbl = [-1, -1, -1, -1, 2, 4, 6, 8, -1, -1, -1, -1, 2, 4, 6, 8];
    const steptbl = [
      7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 19, 21, 23, 25, 28, 31,
      34, 37, 41, 45, 50, 55, 60, 66, 73, 80, 88, 97, 107, 118, 130, 143,
      157, 173, 190, 209, 230, 253, 279, 307, 337, 371, 408, 449, 494, 544,
      598, 658, 724, 796, 876, 963, 1060, 1166, 1282, 1411, 1552, 1707, 1878, 2066,
      2272, 2499, 2749, 3024, 3327, 3660, 4026, 4428, 4871, 5358, 5894, 6484, 7132, 7845, 8630, 9493,
      10442, 11487, 12635, 13899, 15289, 16818, 18500, 20350, 22385, 24623, 27086, 29794, 32767
    ];

    // ADPCM 解码函数 - 从index.html复制过来
    function adpcmToPcm(ps, pd) {
      let sampleCount = ps[3] * 2;
      let predict = (ps[0] | (ps[1] << 8)) << 16 >> 16;
      let predict_idx = ps[2];

      let pcode = ps.slice(4);
      let code = pcode.shift();

      for (let i = 0; i < sampleCount; i++) {
        let step = steptbl[predict_idx];
        let diffq = step >> 3;
        if (code & 4) diffq += step;
        step >>= 1;
        if (code & 2) diffq += step;
        step >>= 1;
        if (code & 1) diffq += step;

        if (code & 8) predict -= diffq;
        else predict += diffq;

        if (predict > 32767) predict = 32767; else if (predict < -32768) predict = -32768;
        predict_idx += idxtbl[code & 15];
        if (predict_idx < 0) predict_idx = 0; else if (predict_idx > 88) predict_idx = 88;

        if (i & 1) {
          code = pcode.shift();
        } else {
          code >>= 4;
        }
        pd.push(predict & 0xFF);
        pd.push((predict >> 8) & 0xFF);
      }
    }

    // PCM 转 WAV - 从index.html复制过来
    function pcmToWav(pcmData, sampleRate = 16000) {
      const dataSize = pcmData.length;
      const buffer = new ArrayBuffer(44 + dataSize);
      const view = new DataView(buffer);

      writeString(view, 0, 'RIFF');
      view.setUint32(4, 36 + dataSize, true);
      writeString(view, 8, 'WAVE');
      writeString(view, 12, 'fmt ');
      view.setUint32(16, 16, true);
      view.setUint16(20, 1, true);
      view.setUint16(22, 1, true);
      view.setUint32(24, sampleRate, true);
      view.setUint32(28, sampleRate * 2, true);
      view.setUint16(32, 2, true);
      view.setUint16(34, 16, true);
      writeString(view, 36, 'data');
      view.setUint32(40, dataSize, true);

      let offset = 44;
      for (let i = 0; i < dataSize; i += 2) {
        const sample = (pcmData[i + 1] << 8) | pcmData[i];
        view.setInt16(offset, sample, true);
        offset += 2;
      }

      return new Blob([buffer], { type: 'audio/wav' });
    }

    function writeString(dv, offset, str) {
      for (let i = 0; i < str.length; i++) {
        dv.setUint8(offset + i, str.charCodeAt(i));
      }
    }

    // 在全局变量区域添加连接状态和缓冲区
    let connectionEstablished = false; // 标记WebSocket连接是否已真正建立
    let dataBufferEnabled = false;    // 是否启用数据缓冲
    let pendingDataBuffer = [];       // 暂存未发送的数据
    const MAX_BUFFER_SIZE = 20;       // 最大缓冲区大小
    let lastConnectionTime = 0;       // 上次连接时间
    const MIN_RECONNECT_INTERVAL = 2000; // 最小重连间隔(ms)

    // 添加数据处理安全检查标志
    let azureSafetyChecksEnabled = true;  // 开启额外的数据安全检查

    // 在全局变量区域添加重试相关变量
    let connectionRetryCount = 0;
    const MAX_RETRY_COUNT = 3;
    const RETRY_DELAY = 2000; // 2秒
    const REGION_FAILOVER = ["westus", "eastus", "eastasia"]; // 区域故障转移选项

    // 检查Azure服务可用性
    async function checkAzureServiceAvailability() {
      console.log("检查Azure服务可用性...");
      try {
        // 尝试获取令牌来验证服务可用性
        const response = await fetch(`https://${AZURE_SPEECH_REGION}.api.cognitive.microsoft.com/sts/v1.0/issuetoken`, {
          method: 'POST',
          headers: {
            'Ocp-Apim-Subscription-Key': AZURE_SPEECH_KEY
          }
        });

        if (response.ok) {
          console.log("Azure服务可用");
          return true;
        } else {
          console.error(`Azure服务不可用，HTTP状态: ${response.status}`);
          return false;
        }
      } catch (error) {
        console.error("Azure服务检查失败:", error);
        return false;
      }
    }

    // 增强的初始化识别器函数
    function initBLERecognizer() {
      try {
        console.log("Initializing speech recognizer...");

        if (!AZURE_SPEECH_KEY || AZURE_SPEECH_KEY.trim() === "") {
          console.error("Azure speech key not set");
          return null;
        }

        connectionEstablished = false;
        recognizerInitComplete = false;

        const speechConfig = SpeechSDK.SpeechConfig.fromSubscription(AZURE_SPEECH_KEY, AZURE_SPEECH_REGION);

        // Language configuration
        let recognitionLanguage = "en-US"; // Default
        const languageMap = {
          'zh': 'zh-CN',
          'en': 'en-US',
          'fr': 'fr-FR',
          'es': 'es-ES',
          'de': 'de-DE',
          'it': 'it-IT',
          'ja': 'ja-JP',
          'ko': 'ko-KR',
          'ru': 'ru-RU',
          'pt': 'pt-BR',
          'ar': 'ar-AE',
          'hi': 'hi-IN',
          'tr': 'tr-TR',
          'nl': 'nl-NL',
          'pl': 'pl-PL'
        };

        // Set up auto language detection
        const autoDetectConfig = new SpeechSDK.AutoDetectSourceLanguageConfig(
          Object.values(languageMap),
          "en-US" // Default language if detection fails
        );

        // Create the push stream for audio data
        const pushStream = SpeechSDK.AudioInputStream.createPushStream();
        const audioConfig = SpeechSDK.AudioConfig.fromStreamInput(pushStream);

        // Create recognizer based on whether we have a main language set
        let recognizer;
        if (mainLanguage && languageMap[mainLanguage]) {
          // Use specific language
          speechConfig.speechRecognitionLanguage = languageMap[mainLanguage];
          recognizer = new SpeechSDK.SpeechRecognizer(speechConfig, audioConfig);
          console.log(`Created recognizer for specific language: ${languageMap[mainLanguage]}`);
        } else {
          // Use auto detection
          console.log("Setting up auto-detection with languages:", Object.values(languageMap));
          const autoDetectSourceLanguageConfig = new SpeechSDK.AutoDetectSourceLanguageConfig(
            Object.values(languageMap),
            "en-US" // Default language if detection fails
          );

          recognizer = new SpeechSDK.SpeechRecognizer(
            speechConfig,
            audioConfig,
            autoDetectSourceLanguageConfig
          );
          console.log("Created auto-detecting recognizer");
        }

        // Store push stream reference
        recognizer.pushStream = pushStream;

        // Set up event handlers with detailed logging
        recognizer.recognizing = (s, e) => {
          console.log("[Recognizing Event]", {
            reason: e.result.reason,
            text: e.result.text,
            offset: e.result.offset,
            duration: e.result.duration
          });

          if (e.result.reason === SpeechSDK.ResultReason.RecognizingSpeech) {
            const text = e.result.text || "";
            if (text.trim()) {
              console.log("[Recognizing] Interim result:", text);

              // Update current partial text
              currentPartialText = text;

              // Construct display text
              let displayText = accumulatedText;
              if (displayText && !displayText.endsWith(".") && !displayText.endsWith("。")) {
                displayText += " ";
              }
              displayText += currentPartialText;

              console.log("[Recognizing] Display text:", {
                accumulatedText,
                currentPartialText,
                finalDisplay: displayText
              });

              // Update display
              inputText.value = displayText;
              inputText.scrollTop = inputText.scrollHeight;

              // Trigger real-time translation
              performRealTimeTranslation(displayText);
            }
          }
        };

        recognizer.recognized = (s, e) => {
          console.log("[Recognized Event]", {
            reason: e.result.reason,
            text: e.result.text,
            offset: e.result.offset,
            duration: e.result.duration
          });

          if (e.result.reason === SpeechSDK.ResultReason.RecognizedSpeech) {
            const text = e.result.text || "";
            if (text.trim()) {
              console.log("[Recognized] Final result:", text);

              // Get detected language if available
              let detectedLang = null;
              if (e.result.properties) {
                try {
                  const langCode = e.result.properties.getProperty(
                    SpeechSDK.PropertyId.SpeechServiceConnection_RecoLanguage
                  );
                  if (langCode) {
                    detectedLang = langCode.split('-')[0];
                    console.log("[Recognized] Detected language:", detectedLang);
                  }
                } catch (err) {
                  console.warn("[Recognized] Failed to get language:", err);
                }
              }

              // Update accumulated text
              if (accumulatedText) {
                if (!accumulatedText.endsWith(".") && !accumulatedText.endsWith("。")) {
                  accumulatedText += " ";
                }
                accumulatedText += text;
              } else {
                accumulatedText = text;
              }

              console.log("[Recognized] Updated text:", {
                previousAccumulated: accumulatedText,
                newText: text,
                finalAccumulated: accumulatedText
              });

              // Clear partial text since we have a final result
              currentPartialText = "";

              // Update display
              inputText.value = accumulatedText;
              inputText.scrollTop = inputText.scrollHeight;

              // Update connection status
              connectionEstablished = true;
              azureConnectionFailed = false;
              connectionRetryCount = 0;

              // Trigger translation
              performRealTimeTranslation(accumulatedText);
            }
          } else if (e.result.reason === SpeechSDK.ResultReason.NoMatch) {
            console.warn("[Recognized] No match:", e.result.noMatchDetails);
          }
        };

        // Session events with detailed logging
        recognizer.sessionStarted = (s, e) => {
          console.log("[Session] Started", {
            isNewSession: isNewRecordingSession,
            sessionId: e.sessionId
          });

          if (isNewRecordingSession) {
            console.log("[Session] Clearing text for new session");
            accumulatedText = "";
            currentPartialText = "";
            inputText.value = "";
            translatedText.value = "";
          } else {
            console.log("[Session] Continuing with existing text:", accumulatedText);
          }
        };

        recognizer.sessionStopped = (s, e) => {
          console.log("[Session] Stopped", {
            finalText: accumulatedText
          });
        };

        // Connection monitoring with detailed logging
        const connection = SpeechSDK.Connection.fromRecognizer(recognizer);

        connection.connected = (e) => {
          console.log("[Connection] Connected", {
            timestamp: new Date().toISOString()
          });
          connectionEstablished = true;
        };

        connection.disconnected = (e) => {
          console.log("[Connection] Disconnected", {
            timestamp: new Date().toISOString()
          });
          connectionEstablished = false;
        };

        // Add error handler
        recognizer.canceled = (s, e) => {
          console.error("[Error] Recognition canceled", {
            reason: e.reason,
            errorCode: e.errorCode,
            errorDetails: e.errorDetails
          });
        };

        return recognizer;
      } catch (error) {
        console.error("Failed to initialize recognizer:", error);
        return null;
      }
    }

    // 防抖翻译函数
    let translationDebounceTimer = null;
    let lastTranslatedText = "";
    let translating = false;

    // 新增一个快速翻译函数，专门用于实时转写
    function performRealTimeTranslation(text) {
      if (!text || !text.trim() || text === lastTranslatedText || translating || text === "正在转写..." || text === "正在转写") {
        return;
      }

      // 短文本不翻译，等累积到一定程度再翻译，提高效率
      if (text.length < 5) {
        return;
      }

      // 取消之前的防抖计时器
      if (translationDebounceTimer) {
        clearTimeout(translationDebounceTimer);
      }

      // 使用较短的延迟进行实时翻译
      translationDebounceTimer = setTimeout(async () => {
        translating = true;
        try {
          // 确定目标语言
          let actualTargetLang = targetLanguage;
          if (!actualTargetLang) {
            const detectedRaw = await detectLanguageByChatGPT(text);
            const detectedLang = normalizeLang(detectedRaw);
            actualTargetLang = detectedLang === 'en' ? 'zh' : 'en';
          }

          // 翻译文本
          const translated = await translateByChatGPT(text, actualTargetLang);

          if (translated) {
            // 只更新翻译文本显示，不播放TTS
            translatedText.value = translated;
            lastTranslatedText = text;
          }

        } catch (err) {
          console.error("翻译错误:", err);
        } finally {
          translating = false;
        }
      }, 300);  // 使用更短的延迟时间，但不要太短，避免频繁API调用
    }

    async function debouncedTranslate(text, forcedTargetLang = null) {
      if (translationDebounceTimer) {
        clearTimeout(translationDebounceTimer);
      }

      // 如果文本与上次翻译的相同，跳过
      if (text === lastTranslatedText) {
        return;
      }

      translationDebounceTimer = setTimeout(async () => {
        if (!text.trim() || translating) return;

        translating = true;
        try {
          // 检测语言
          const detectedRaw = await detectLanguageByChatGPT(text);
          const detectedLang = normalizeLang(detectedRaw);

          // 确定目标语言
          let actualTargetLang = forcedTargetLang;
          if (!actualTargetLang) {
            // 当没有指定目标语言时，遵循OpenAI的逻辑
            actualTargetLang = detectedLang === 'en' ? 'zh' : 'en';
          }

          const translated = await translateByChatGPT(text, actualTargetLang);

          // 更新显示：原文在左侧，翻译在右侧
          translatedText.value = translated;
          lastTranslatedText = text;

          console.log(`翻译完成: ${detectedLang} => ${actualTargetLang}`);
        } catch (err) {
          console.error("翻译错误:", err);
        } finally {
          translating = false;
        }
      }, 800);  // 800毫秒延迟
    }

    // 处理蓝牙麦克风数据 - 修改版本
    async function handleVoiceData(event) {
      try {
        const adpcmData = new Uint8Array(event.target.value.buffer);
        // console.log("[Voice Data] Received data length:", adpcmData.length);

        // 确定哪个麦克风发送的数据
        let micIndex = -1;
        for (let i = 0; i < voiceDataCharacteristics.length; i++) {
          if (voiceDataCharacteristics[i] && event.target === voiceDataCharacteristics[i]) {
            micIndex = i;
            break;
          }
        }

        if (micIndex === -1) {
          micIndex = activeMicIndex;
          if (micIndex === -1) {
            console.warn("无法确定数据来源的麦克风，忽略数据包");
            return;
          }
        }

        // 检查数据包长度和ADPCM头部
        if (adpcmData.length === 128) {
          // 解析ADPCM头部
          const predict = (adpcmData[0] | (adpcmData[1] << 8));
          const predict_idx = adpcmData[2];
          const audioLength = adpcmData[3];

          // console.log(`[数据包分析] 麦克风 ${micIndex+1}:`, {
          //   数据长度: adpcmData.length,
          //   前8字节: Array.from(adpcmData.slice(0, 8)).map(b => '0x' + b.toString(16).padStart(2, '0')).join(' '),
          //   ADPCM头部: {
          //     predict值: predict,
          //     predict_idx值: predict_idx,
          //     音频数据长度: audioLength
          //   },
          //   时间戳: new Date().toISOString()
          // });

          // 检测按钮按下 - 基于观察到的模式
          if (predict === 1001 && predict_idx === 27 && audioLength === 124) {
            console.log('[按钮事件] 检测到按钮按下');
            if (!isBluetoothRecording) {
              // 停止当前TTS播放
              stopCurrentTTS();

              // 标记为新的录音会话
              isNewRecordingSession = true;
              recordingSessionId = Date.now();

              // 清空所有文本状态
              accumulatedText = "";
              currentPartialText = "";
              inputText.value = "";
              translatedText.value = "";

              // 重置录音状态
              resetRecordingState(true); // true表示清空input
              activeMicIndex = micIndex; // 设置当前活动麦克风

              // 开始录音
              startBluetoothRecording();
            }
            return;
          }

          // 检测按钮释放 - 基于观察到的模式
          if (predict === 65448 && predict_idx === 25 && audioLength === 124) {
            console.log('[按钮事件] 检测到按钮释放');
            if (isBluetoothRecording && activeMicIndex === micIndex) {
              // 设置按钮触发标志，防止超时检查
              buttonTriggeredStop = true;

              // 立即停止所有计时器
              stopRecordingTimers();

              // 清除数据检查定时器
              if (checkDataTimeoutInterval) {
                clearInterval(checkDataTimeoutInterval);
                checkDataTimeoutInterval = null;
              }

              // 清除流式转写定时器
              if (streamTranscribeTimeoutId) {
                clearTimeout(streamTranscribeTimeoutId);
                streamTranscribeTimeoutId = null;
              }

              // 先设置状态防止其他处理
              isBluetoothRecording = false;

              // 停止Azure识别器
              if (bleRecognizer) {
                try {
                  await stopAzureRecognizer();
                } catch (e) {
                  console.error('停止Azure识别器时出错:', e);
                }
              }

              // 处理录音数据
              if (fullPcmDataArray.length > 1000) {
                isProcessingData = true;
                processingStartTime = Date.now();

                // 更新UI为处理中状态
                const micBtn = activeMicIndex === 0 ? gmicMicBtn : gmicMicBtn2;
                micBtn.innerHTML = '<i class="fas fa-cog fa-spin"></i> 处理中...';

                try {
                  await processPcmData(true);

                  // 处理完成后，确保UI更新为就绪状态
                  micBtn.classList.remove('recording');
                  micBtn.classList.add('waiting');
                  micBtn.innerHTML = `<i class="fas fa-microphone"></i> GMIC ${micIndex + 1} Ready`;
                } catch (error) {
                  console.error('处理录音数据时出错:', error);
                }
              }

              // 结束当前录音会话
              isNewRecordingSession = false;
              recordingSessionId = null;
              buttonTriggeredStop = false;
            }
            return;
          }

          // 如果是普通的语音数据包，继续处理
          if (!isBluetoothRecording && !isProcessingData) {
            console.log(`收到麦克风 ${micIndex + 1} 语音数据，但未开始录音，自动开始录音`);

            // 清空输入文本
            inputText.value = "";
            translatedText.value = "";

            activeMicIndex = micIndex; // 设置当前活动麦克风
            startBluetoothRecording();
          }

          // 更新最后数据接收时间
          lastDataReceivedTime = Date.now();

          // 解码ADPCM数据为PCM
          try {
            const decodedData = decodeADPCM(adpcmData);

            // 将解码后的PCM数据添加到数组中
            const array = new Uint8Array(decodedData.buffer);
            for (let i = 0; i < array.length; i++) {
              fullPcmDataArray.push(array[i]);
            }

            // 实时发送数据到Azure识别器
            if (bleRecognizer && bleRecognizer.pushStream && connectionEstablished) {
              try {
                // console.log("[Voice Data] Sending to Azure recognizer, data size:", decodedData.buffer.byteLength);
                bleRecognizer.pushStream.write(decodedData.buffer);
              } catch (e) {
                console.error("[Voice Data] Failed to send to Azure recognizer:", e);
              }
            } else {
              // console.log("[Voice Data] Skipped sending to Azure:", {
              //   hasRecognizer: !!bleRecognizer,
              //   hasPushStream: !!(bleRecognizer && bleRecognizer.pushStream),
              //   isConnected: connectionEstablished
              // });
            }
          } catch (error) {
            console.error(`解码麦克风 ${micIndex + 1} ADPCM数据失败:`, error);
          }
        }

      } catch (error) {
        console.error("处理语音数据主函数出错:", error);
      }
    }

    // 新增函数：专门用于停止录音相关的计时器
    function stopRecordingTimers() {
      // 清除录音时长计时器
      if (bleRecordTimer) {
        console.log("停止录音计时器");
        clearInterval(bleRecordTimer);
        bleRecordTimer = null;
      }

      // 清除数据检查计时器
      if (checkDataTimeoutInterval) {
        console.log("停止数据检查计时器");
        clearInterval(checkDataTimeoutInterval);
        checkDataTimeoutInterval = null;
      }
    }

    // 修改checkDataTimeout函数，添加按钮触发标志
    let buttonTriggeredStop = false;  // 添加全局变量

    function checkDataTimeout() {
      // 如果已经在处理数据或已经停止录音，则不进行任何操作
      if (isProcessingData || !isBluetoothRecording || buttonTriggeredStop) {
        return;
      }

      const now = Date.now();
      // 只在实际录音过程中检查超时
      if (now - lastDataReceivedTime > dataTimeout && isBluetoothRecording) {
        console.log("等待用户继续说话...", isBluetoothRecording);
      }
    }

    async function processPcmData(isSignalTriggered = false) {
      // 双重检查，确保不会重复处理
      if (!isProcessingData) {
        console.log("processPcmData被调用，但isProcessingData为false，中止处理");
        return;
      }

      console.log("处理音频数据...");

      // 设置处理超时，防止处理卡死
      if (processingTimeoutId) {
        clearTimeout(processingTimeoutId);
      }
      processingTimeoutId = setTimeout(() => {
        console.error(`数据处理超时(${MAX_PROCESSING_TIME}ms)，强制重置状态`);
        // 如果处理超时，强制重置状态
        isProcessingData = false;
        resetRecordingState(false);
        const activeMicBtn = activeMicIndex === 0 ? gmicMicBtn : gmicMicBtn2;
        activeMicBtn.classList.remove('recording');
        activeMicBtn.classList.add('waiting');
        activeMicBtn.innerHTML = `<i class="fas fa-microphone"></i> GMIC Ready`;
      }, MAX_PROCESSING_TIME);

      try {
        // 转换PCM数据为WAV格式
        let audioBlob = pcmToWav(fullPcmDataArray, 16000);

        // 保存当前录音以便添加到历史记录
        currentAudioBlob = audioBlob;

        // 获取已有的转写文本（流式转写已经填充）
        let existingText = inputText.value.trim();

        // 如果已有文本包含"正在转写..."或者为空，则发送到Whisper重新进行完整识别
        if (!existingText || existingText === "正在转写..." || existingText.endsWith("...")) {
          const activeMicBtn = activeMicIndex === 0 ? gmicMicBtn : gmicMicBtn2;
          activeMicBtn.innerHTML = '<i class="fas fa-cog fa-spin"></i> 最终转写中...';

          // 发送到Whisper进行完整识别
          await sendToWhisper(audioBlob);
        } else {
          console.log("使用现有转写文本:", existingText);

          // 使用流式转写已有的文本进行翻译
          await handleInput(existingText);
        }

        // 获取翻译后的文本用于TTS
        const translatedContent = translatedText.value.trim();
        if (translatedContent) {
          // 检测翻译文本的语言，用于TTS
          let ttsLang = targetLanguage;
          if (!ttsLang) {
            try {
              ttsLang = await detectLanguageByChatGPT(translatedContent);
              console.log("TTS语言检测结果:", ttsLang);
            } catch (e) {
              console.error("语言检测失败，使用默认语言:", e);
              ttsLang = "en"; // 默认使用英语
            }
          }

          // 生成并播放TTS
          // console.log("播放翻译结果的TTS...");
          // await speakTextByAzureTTS(translatedContent, ttsLang);
        } else {
          console.warn("翻译结果为空，跳过TTS生成");
        }

        console.log("音频处理完成");
      } catch (error) {
        console.error("处理音频数据时出错:", error);
      } finally {
        // 清除处理超时
        if (processingTimeoutId) {
          clearTimeout(processingTimeoutId);
        }

        console.log("processPcmData完成，开始重置状态");
        // 确保处理状态被重置
        isProcessingData = false;

        // 重置录音状态，但不清除input text
        resetRecordingState(false);

        // 确保UI更新为Ready状态
        const activeMicBtn = activeMicIndex === 0 ? gmicMicBtn : gmicMicBtn2;
        activeMicBtn.classList.remove('recording');
        activeMicBtn.classList.add('waiting');
        activeMicBtn.innerHTML = `<i class="fas fa-microphone"></i> GMIC Ready`;

        console.log("录音会话完全重置，准备好下次录音");
      }
    }

    function startBluetoothRecording() {
      console.log("开始蓝牙录音...");

      // 停止当前TTS播放
      stopCurrentTTS();

      // 防止重复启动
      if (isBluetoothRecording && !isProcessingData) {
        console.log("已经在录音中，忽略此次启动请求");
        isRecognizerInitializing = false; // 重置初始化标志
        return;
      }

      // 只有在新会话时才清空文本
      if (isNewRecordingSession) {
        console.log("新录音会话，清空文本");
        inputText.value = "";
        translatedText.value = "";
        accumulatedText = "";
        currentPartialText = "";
      } else {
        console.log("继续现有会话，保留文本");
      }

      // 重置录音状态变量 - 更彻底地清理所有状态
      isBluetoothRecording = true;
      fullPcmDataArray = [];
      lastDataReceivedTime = Date.now();
      lastTranscribeTime = 0;
      streamTranscriptionInProgress = false;

      // 只在新会话时重置transcribedText
      if (isNewRecordingSession) {
        transcribedText = "";
      }

      // 重置实时转写首次接收标志
      window.hasFirstTranscription = false;

      // 启动录音时长计时器
      bleRecordStartTime = Date.now();
      if (bleRecordTimer) {
        clearInterval(bleRecordTimer);
      }
      bleRecordTimer = setInterval(updateBleRecordingTime, 500);

      // 更新UI状态
      const activeMicBtn = activeMicIndex === 0 ? gmicMicBtn : gmicMicBtn2;
      activeMicBtn.classList.remove('waiting');
      activeMicBtn.classList.add('recording');
      activeMicBtn.innerHTML = '<i class="fas fa-microphone"></i> GMIC 录音中... (00:00)';

      // 启动数据检查定时器
      if (checkDataTimeoutInterval) {
        clearInterval(checkDataTimeoutInterval);
      }
      checkDataTimeoutInterval = setInterval(checkDataTimeout, 500);

      // 启动Azure识别 - 确保识别器是活跃的
      if (!bleRecognizer || azureConnectionFailed) {
        console.log("初始化Azure语音识别器...");
        bleRecognizer = initBLERecognizer();

        if (bleRecognizer) {
          // 启动识别
          console.log("启动新创建的Azure识别器...");
          startBLEAzureRecognition();
        } else {
          console.warn("无法初始化Azure识别器，将只使用Whisper进行流式转写");
        }
      } else {
        // 检查识别器状态并确保其正在运行
        try {
          // 尝试重新启动识别
          console.log("尝试确保Azure识别器正在运行...");
          // 清理旧的recognizer连接
          bleRecognizer.stopContinuousRecognitionAsync(
            () => {
              console.log("已停止旧的识别器");
              // 重新启动
              startBLEAzureRecognition();
            },
            (err) => {
              console.warn("停止旧识别器失败:", err);
              // 仍然尝试启动
              startBLEAzureRecognition();
            }
          );
        } catch (e) {
          console.error("操作Azure识别器失败:", e);
          // 重置并重新创建
          try {
            if (bleRecognizer) {
              bleRecognizer.close();
            }
          } catch (e2) { }

          bleRecognizer = initBLERecognizer();
          if (bleRecognizer) {
            startBLEAzureRecognition();
          }
        }
      }

      // 确保连接状态正确
      connectionEstablished = true;
    }

    // 完全分离创建和启动新识别器的逻辑
    async function createAndStartNewRecognizer() {
      try {
        // 检查是否需要等待冷却期
        const now = Date.now();
        const timeSinceLastUse = now - lastSpeechServiceUseTime;

        if (lastSpeechServiceUseTime > 0 && timeSinceLastUse < DIFFERENT_SESSIONS_DELAY) {
          // 需要等待完成冷却期
          const waitTime = DIFFERENT_SESSIONS_DELAY - timeSinceLastUse;
          console.log(`等待语音服务冷却期 ${waitTime}ms...`);
          await new Promise(resolve => setTimeout(resolve, waitTime));
        }

        // 强制清理WebSocket连接
        forceCleanupWebSockets();

        // 确保旧实例已完全停止
        if (bleRecognizer) {
          console.log("停止旧识别器并进行清理");
          try {
            await stopAzureRecognizer();
          } catch (e) {
            console.error("停止旧识别器时出错:", e);
          }
          // 额外冷却时间
          await new Promise(resolve => setTimeout(resolve, RECONNECT_DELAY));
        } else {
          console.log("无旧识别器，直接创建新识别器");
        }

        // 初始化新识别器 - 使用默认区域
        console.log("初始化新识别器...");
        bleRecognizer = initBLERecognizer();
        if (!bleRecognizer) {
          console.error("识别器初始化失败");
          azureConnectionFailed = true;
          return null;
        }

        // 更新最后使用时间
        lastSpeechServiceUseTime = Date.now();

        // 启动连续识别
        console.log("启动语音识别...");
        return new Promise((resolve, reject) => {
          bleRecognizer.startContinuousRecognitionAsync(
            () => {
              console.log("Azure识别器启动成功");
              resolve(bleRecognizer);
            },
            (error) => {
              console.error("Azure识别器启动失败:", error);
              azureConnectionFailed = true;
              reject(error);
            }
          );
        });
      } catch (error) {
        console.error("创建识别器时出错:", error);
        azureConnectionFailed = true;
        return null;
      }
    }

    // 重置录音状态的函数
    function resetRecordingState(clearInputText = true) {
      console.log("重置录音状态 - 完全清理");

      // 清除流式转写定时器
      if (streamTranscribeTimeoutId) {
        clearTimeout(streamTranscribeTimeoutId);
        streamTranscribeTimeoutId = null;
      }

      // 清除识别器初始化超时计时器
      if (initRecognizerTimeout) {
        clearTimeout(initRecognizerTimeout);
        initRecognizerTimeout = null;
      }

      // 先停止所有计时器
      stopRecordingTimers();

      // 停止Azure识别器
      if (bleRecognizer) {
        try {
          bleRecognizer.stopContinuousRecognitionAsync(
            () => {
              console.log("Azure识别器已停止");
              // 可选：完全关闭识别器
              try {
                bleRecognizer.close();
                bleRecognizer = null;
              } catch (e) {
                console.error("关闭Azure识别器时出错:", e);
              }
            },
            (err) => {
              console.error("停止Azure识别器失败:", err);
            }
          );
        } catch (e) {
          console.error("停止Azure识别器时出错:", e);
          // 强制关闭
          try {
            bleRecognizer.close();
            bleRecognizer = null;
          } catch (e2) { }
        }
      }

      // 重置关键状态变量
      isBluetoothRecording = false;
      isProcessingData = false;
      isRecognizerInitializing = false;
      streamTranscriptionInProgress = false;
      lastTranscribeTime = 0;
      lastButtonSignal = -1;
      activeMicIndex = -1; // 重置当前活动麦克风

      // 重置转写状态变量
      currentPartialText = "";
      accumulatedText = "";
      lastTranscribedText = "";

      // 重置其他状态
      fullPcmDataArray = [];
      dataSendCounter = 0;
      totalDataSent = 0;
      detectedLanguage = null; // 重置检测到的语言

      // 根据参数决定是否清空输入框
      if (clearInputText) {
        console.log("清空输入文本");
        inputText.value = "";
        translatedText.value = "";
        transcribedText = "";
      }

      // 重置录音会话状态
      isNewRecordingSession = false;
      recordingSessionId = null;

      console.log("录音状态已完全重置，所有变量已清理");
    }

    function updateStatusUI() {
      document.getElementById("spanMainLang").innerText = mainLanguage || "unset";
      document.getElementById("spanTargetLang").innerText = targetLanguage || "unset";
    }

    function getDateTimeString() {
      const d = new Date();
      const mm = String(d.getMonth() + 1).padStart(2, "0");
      const dd = String(d.getDate()).padStart(2, "0");
      const hh = String(d.getHours()).padStart(2, "0");
      const min = String(d.getMinutes()).padStart(2, "0");
      const sec = String(d.getSeconds()).padStart(2, "0");
      return mm + "/" + dd + " " + hh + ":" + min + ":" + sec;
    }

    function appendLog(originalText, translatedText, originalAudioBlob = null, ttsAudioBlob = null) {
      const container = document.getElementById("logContainer");
      const logItem = document.createElement("div");
      logItem.className = "log-item";
      const timestamp = getDateTimeString();

      const pTimestamp = document.createElement("p");
      pTimestamp.textContent = timestamp;
      logItem.appendChild(pTimestamp);

      const pOrig = document.createElement("p");
      pOrig.textContent = originalText;
      logItem.appendChild(pOrig);

      const pTrans = document.createElement("p");
      pTrans.textContent = translatedText;
      logItem.appendChild(pTrans);

      // 添加音频控制元素
      const audioControls = document.createElement("div");
      audioControls.className = "audio-controls";
      let hasDurationInfo = false;

      // 添加用户录音播放按钮
      if (originalAudioBlob) {
        const origAudioBtn = document.createElement("button");
        origAudioBtn.className = "audio-btn";
        origAudioBtn.innerHTML = '<i class="fas fa-play"></i> 原录音';

        // 获取音频时长并显示
        getAudioDuration(originalAudioBlob).then(duration => {
          if (duration) {
            origAudioBtn.innerHTML += ` ${formatDuration(duration)}`;
            hasDurationInfo = true;
          }
        });

        origAudioBtn.onclick = function () {
          playAudioBlob(originalAudioBlob);
        };
        audioControls.appendChild(origAudioBtn);
      }

      // 添加TTS播放按钮
      if (ttsAudioBlob) {
        const ttsAudioBtn = document.createElement("button");
        ttsAudioBtn.className = "audio-btn";
        ttsAudioBtn.innerHTML = '<i class="fas fa-play"></i> TTS';

        // 获取音频时长并显示
        getAudioDuration(ttsAudioBlob).then(duration => {
          if (duration) {
            ttsAudioBtn.innerHTML += ` ${formatDuration(duration)}`;
            hasDurationInfo = true;
          }
        });

        ttsAudioBtn.onclick = function () {
          playAudioBlob(ttsAudioBlob);
        };
        audioControls.appendChild(ttsAudioBtn);
      }
      // 如果没有TTS音频，添加生成TTS按钮
      else if (translatedText) {
        const generateTTSBtn = document.createElement("button");
        generateTTSBtn.className = "audio-btn generate-tts";
        generateTTSBtn.innerHTML = '<i class="fas fa-volume-up"></i> 生成TTS';

        generateTTSBtn.onclick = async function () {
          // 禁用按钮避免重复点击
          generateTTSBtn.disabled = true;
          generateTTSBtn.textContent = "生成中...";

          // 检测语言，如果之前已有翻译目标语言，使用它
          let lang = sessionTranslationTarget;

          if (!lang) {
            // 尝试检测语言
            try {
              const detectedRaw = await detectLanguageByChatGPT(translatedText);
              lang = normalizeLang(detectedRaw);
            } catch (err) {
              console.error("TTS语言检测失败:", err);
              lang = "en"; // 默认使用英语
            }
          }

          // 生成并播放TTS
          try {
            await speakTextByAzureTTS(translatedText, lang);
            console.log("播放翻译结果的TTS 2...");

            // 如果生成成功且有新的TTS Blob
            if (currentTTSBlob) {
              // 替换按钮为播放按钮
              const ttsAudioBtn = document.createElement("button");
              ttsAudioBtn.className = "audio-btn";
              ttsAudioBtn.innerHTML = '<i class="fas fa-play"></i> TTS';

              // 获取音频时长并显示
              getAudioDuration(currentTTSBlob).then(duration => {
                if (duration) {
                  ttsAudioBtn.innerHTML += ` ${formatDuration(duration)}`;
                }
              });

              const ttsBlobCopy = currentTTSBlob; // 创建引用副本
              ttsAudioBtn.onclick = function () {
                playAudioBlob(ttsBlobCopy);
              };

              // 替换按钮
              generateTTSBtn.parentNode.replaceChild(ttsAudioBtn, generateTTSBtn);

              // 更新历史记录
              const index = audioHistory.findIndex(item =>
                item.timestamp === timestamp &&
                item.originalText === originalText &&
                item.translatedText === translatedText);

              if (index !== -1) {
                audioHistory[index].ttsAudio = ttsBlobCopy;
              }
            } else {
              // 如果生成失败，恢复按钮状态
              generateTTSBtn.disabled = false;
              generateTTSBtn.innerHTML = '<i class="fas fa-volume-up"></i> 重试生成';
            }
          } catch (err) {
            console.error("TTS生成失败:", err);
            generateTTSBtn.disabled = false;
            generateTTSBtn.innerHTML = '<i class="fas fa-volume-up"></i> 重试生成';
          }
        };

        audioControls.appendChild(generateTTSBtn);
      }

      if (audioControls.children.length > 0) {
        logItem.appendChild(audioControls);
      }

      if (container.firstChild) {
        container.insertBefore(logItem, container.firstChild);
      } else {
        container.appendChild(logItem);
      }

      // 保存到历史记录数组
      audioHistory.push({
        timestamp: timestamp,
        originalText: originalText,
        translatedText: translatedText,
        originalAudio: originalAudioBlob,
        ttsAudio: ttsAudioBlob
      });
    }

    // 播放音频Blob的函数
    function playAudioBlob(blob) {
      // 先停止当前TTS播放
      stopCurrentTTS();

      const url = URL.createObjectURL(blob);
      const audioElement = document.getElementById("ttsAudio");
      audioElement.src = url;
      audioElement.load();

      // 应用保存的播放速度
      audioElement.playbackRate = savedPlaybackSpeed;

      audioElement.play();

      // 更新播放按钮状态
      document.getElementById("playPauseBtn").textContent = "Pause";

      // 播放完成后释放URL
      audioElement.onended = function () {
        URL.revokeObjectURL(url);
      };
    }

    // 停止当前TTS播放
    function stopCurrentTTS() {
      const audioElement = document.getElementById("ttsAudio");
      if (audioElement && !audioElement.paused) {
        audioElement.pause();
        audioElement.currentTime = 0;
        document.getElementById("playPauseBtn").textContent = "Play";
      }
    }

    function normalizeLang(lang) {
      if (!lang) return null;
      let l = lang.toLowerCase();
      const supportedLangs = [
        'zh', 'en', 'fr', 'es', 'de', 'it', 'ja',
        'ko', 'ru', 'pt', 'ar', 'hi', 'tr', 'nl', 'pl'
      ];

      // Handle special cases
      if (l.startsWith('zh')) return 'zh';
      if (l.startsWith('en')) return 'en';
      if (l.startsWith('fr')) return 'fr';
      if (l.startsWith('es')) return 'es';
      if (l.startsWith('de')) return 'de';
      if (l.startsWith('it')) return 'it';
      if (l.startsWith('ja')) return 'ja';
      if (l.startsWith('ko')) return 'ko';
      if (l.startsWith('ru')) return 'ru';
      if (l.startsWith('pt')) return 'pt';
      if (l.startsWith('ar')) return 'ar';
      if (l.startsWith('hi')) return 'hi';
      if (l.startsWith('tr')) return 'tr';
      if (l.startsWith('nl')) return 'nl';
      if (l.startsWith('pl')) return 'pl';

      // If language not in supported list, return null
      return supportedLangs.includes(l) ? l : null;
    }

    // 时间格式化
    function formatTime(sec) {
      const minutes = Math.floor(sec / 60).toString().padStart(2, "0");
      const seconds = Math.floor(sec % 60).toString().padStart(2, "0");
      return minutes + ":" + seconds;
    }

    // 显示/隐藏遮罩层
    function showOverlay() {
      overlay.classList.add("show");
    }
    function hideOverlay() {
      overlay.classList.remove("show");
    }

    // 验证Azure Speech配置
    function validateAzureConfig() {
      if (!AZURE_SPEECH_KEY || AZURE_SPEECH_KEY === "YOUR_AZURE_SPEECH_KEY") {
        console.error("Invalid Azure Speech key");
        return false;
      }
      if (!AZURE_SPEECH_REGION) {
        console.error("Invalid Azure Speech region");
        return false;
      }
      return true;
    }

    // 获取麦克风流
    async function getMicStream() {
      // 如果已经有流，直接返回
      if (micStream) {
        return micStream;
      }

      try {
        // 请求用户麦克风
        const stream = await navigator.mediaDevices.getUserMedia({
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true
          }
        });
        micStream = stream;
        return stream;
      } catch (err) {
        console.error("获取麦克风失败:", err);
        throw err;
      }
    }

    // 初始化Azure识别器 - 电脑麦克风版本
    function initAzureRecognizer(stream) {
      if (typeof SpeechSDK === 'undefined') {
        console.error("Azure Speech SDK not loaded");
        return null;
      }

      try {
        console.log("初始化电脑麦克风Azure识别器...");
        const speechConfig = SpeechSDK.SpeechConfig.fromSubscription(AZURE_SPEECH_KEY, AZURE_SPEECH_REGION);

        // 设置语音识别语言
        speechConfig.speechRecognitionLanguage = mainLanguage || "zh-CN";

        // 启用连续识别模式
        speechConfig.enableDictation();

        // 关键区别：使用fromStreamInput而不是pushStream
        const audioConfig = SpeechSDK.AudioConfig.fromStreamInput(stream);
        const rec = new SpeechSDK.SpeechRecognizer(speechConfig, audioConfig);

        // 实时识别事件
        rec.recognizing = (s, e) => {
          if (e.result && e.result.text) {
            currentPartialText = e.result.text;
            const fullText = accumulatedText +
              (accumulatedText && currentPartialText ? " " : "") +
              currentPartialText;

            // 更新显示 - 保持已有文本，只在末尾添加新的部分
            if (inputText.value && !inputText.value.endsWith(fullText)) {
              inputText.value = inputText.value + " " + text;
            } else if (!inputText.value) {
              inputText.value = text;
            }

            // 实时翻译
            performRealTimeTranslation(inputText.value);
          }
        };

        // 识别完成事件
        rec.recognized = (s, e) => {
          if (e.result && e.result.text) {
            console.log("Recognized text: " + e.result.text);
            // 将完成的识别文本添加到累积文本
            accumulatedText += (accumulatedText ? " " : "") + e.result.text;
            currentPartialText = "";

            // 更新显示 - 保持已有文本，只在末尾添加新的部分
            if (inputText.value && !inputText.value.endsWith(e.result.text)) {
              inputText.value = inputText.value + " " + e.result.text;
            } else if (!inputText.value) {
              inputText.value = e.result.text;
            }

            // 实时翻译
            performRealTimeTranslation(inputText.value);
          }
        };

        // 会话开始事件
        rec.sessionStarted = (s, e) => {
          console.log("Azure Speech session started");
          // 只在新会话时清空文本
          if (isNewRecordingSession) {
            console.log("New session: clearing all text");
            accumulatedText = "";
            currentPartialText = "";
            lastTranslatedText = "";
            inputText.value = "";
            translatedText.value = "";
          } else {
            console.log("Continuing session with accumulated text: " + accumulatedText);
          }
          if (translationDebounceTimer) {
            clearTimeout(translationDebounceTimer);
          }
        };

        rec.sessionStopped = (s, e) => {
          console.log("Azure Speech session stopped");
        };

        return rec;
      } catch (err) {
        console.error("Failed to initialize Azure recognizer:", err);
        return null;
      }
    }

    /*************************************************************
     * 3. 回合制翻译主流程 handleInput
     *************************************************************/
    async function handleInput(userText) {
      if (!userText) return;
      const detectedRaw = await detectLanguageByChatGPT(userText);
      const detectedLang = normalizeLang(detectedRaw) || "unknown";

      let translationTarget = null;
      if (!mainLanguage) {
        // First time
        if (!userHasManualMain) {
          mainLanguage = detectedLang;
        }
        if (!userHasManualTarget) {
          targetLanguage = detectedLang === "en" ? "zh" : "en";
        }
        translationTarget = targetLanguage;
      } else {
        // Subsequent conversations
        if (detectedLang !== mainLanguage) {
          translationTarget = mainLanguage;
          if (!userHasManualTarget) {
            targetLanguage = detectedLang;
          }
        } else {
          if (targetLanguage && targetLanguage !== mainLanguage) {
            translationTarget = targetLanguage;
          } else {
            translationTarget = null;
          }
        }
      }
      updateStatusUI();

      sessionTranslationTarget = translationTarget;

      if (translationTarget && translationTarget === detectedLang) {
        document.getElementById("outputText").value = userText;
        appendLog(userText, userText, currentAudioBlob, null);
        return;
      }

      let translated = userText;
      if (translationTarget) {
        translated = await translateByChatGPT(userText, translationTarget);
      }

      document.getElementById("outputText").value = translated;

      // Only play TTS after final translation is complete
      if (translated && !isBluetoothRecording) {
        await speakTextByAzureTTS(translated, translationTarget || "en");
        console.log("播放翻译结果的TTS 3...");
        appendLog(userText, translated, currentAudioBlob, currentTTSBlob);
        currentAudioBlob = null;
        currentTTSBlob = null;
      } else {
        appendLog(userText, translated, currentAudioBlob, null);
        currentAudioBlob = null;
      }
    }

    // 语言检测 (ChatGPT)
    async function detectLanguageByChatGPT(text) {
      const msgs = [
        {
          role: "system",
          content:
            "You are a language detection tool. Analyze the text and return ONLY the language code of the dominant language (the language with most characters). Return only the short code like 'zh', 'en', 'fr', 'es', 'de', 'it', 'ja', 'ko', 'ru', 'pt', 'ar', 'hi', 'tr', 'nl', 'pl', etc. No explanation."
        },
        { role: "user", content: text }
      ];
      try {
        const resp = await fetch(OPENAI_API_URL, {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "Authorization": "Bearer " + OPENAI_API_KEY
          },
          body: JSON.stringify({
            model: "gpt-3.5-turbo",
            messages: msgs,
            temperature: 0
          })
        });
        const data = await resp.json();
        return (data.choices && data.choices[0].message.content.trim()) || "unknown";
      } catch (err) {
        console.error("detectLanguage fail:", err);
        return "unknown";
      }
    }

    // 翻译 (ChatGPT)
    async function translateByChatGPT(text, targetLang) {
      if (!targetLang) return text;
      const msgs = [
        {
          role: "system",
          content:
            "You are a professional translator. Translate the ENTIRE input text to " + targetLang + " language, regardless of the original languages used. Keep proper nouns, addresses, and numbers as is. Maintain the original format and line breaks. Output only the final translation."
        },
        { role: "user", content: text }
      ];
      try {
        const resp = await fetch(OPENAI_API_URL, {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "Authorization": "Bearer " + OPENAI_API_KEY
          },
          body: JSON.stringify({
            model: "gpt-3.5-turbo",
            messages: msgs,
            temperature: 0
          })
        });
        const data = await resp.json();
        return (data.choices && data.choices[0].message.content.trim()) || "";
      } catch (err) {
        console.error("translate fail:", err);
        return "[translation error]" + text;
      }
    }

    /*************************************************************
     * 4. Azure TTS
     *************************************************************/
    async function speakTextByAzureTTS(text, lang) {
      try {
        // 添加时间戳到翻译文本
        // const timestamp = getTimeStamp();
        // translatedText.value = `${timestamp}\n${text}`;
        translatedText.value = text;

        // 使用OpenAI的TTS API
        console.log(`使用OpenAI TTS API进行语音合成，语言: ${lang}`);

        // 使用gpt-4o-mini-transcribe模型
        const model = "tts-1";

        // 对所有语言统一使用shimmer音色
        const voice = "shimmer";

        // 添加错误处理和超时
        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), 10000); // 10秒超时

        const resp = await fetch(OPENAI_TTS_URL, {
          method: "POST",
          headers: {
            "Authorization": "Bearer " + OPENAI_API_KEY,
            "Content-Type": "application/json"
          },
          body: JSON.stringify({
            model: model,
            input: text,
            voice: voice
          }),
          signal: controller.signal
        });

        clearTimeout(timeoutId);

        if (!resp.ok) {
          throw new Error("OpenAI TTS request failed: " + resp.statusText);
        }

        // OpenAI TTS API直接返回音频数据
        const audioData = await resp.arrayBuffer();
        const blob = new Blob([audioData], { type: "audio/mp3" });

        // 保存TTS Blob用于历史记录
        currentTTSBlob = blob;

        const audioUrl = URL.createObjectURL(blob);

        // 使用已隐藏的 audio 元素播放
        const audioElement = document.getElementById("ttsAudio");

        // 添加事件监听器以确认加载
        const loadPromise = new Promise((resolve, reject) => {
          audioElement.onloadeddata = resolve;
          audioElement.onerror = reject;
        });

        audioElement.src = audioUrl;
        audioElement.load();

        // 等待音频加载完成
        await loadPromise;

        // 应用保存的播放速度
        audioElement.playbackRate = savedPlaybackSpeed;

        // 使用 try-catch 确保播放不会失败
        try {
          const playPromise = audioElement.play();

          if (playPromise !== undefined) {
            playPromise.catch(error => {
              console.error("播放音频失败:", error);
              // 尝试再次播放
              setTimeout(() => {
                audioElement.play().catch(e => console.error("重试播放仍然失败:", e));
              }, 1000);
            });
          }

          // 播放按钮状态更新
          document.getElementById("playPauseBtn").textContent = "Pause";
        } catch (playError) {
          console.error("播放音频出错:", playError);
        }

        console.log(`OpenAI TTS语音合成完成，使用${voice}音色`);
      } catch (err) {
        console.warn("OpenAI TTS语音合成失败:", err);
        // 如果OpenAI TTS失败，尝试退回到Azure TTS
        try {
          console.log("尝试退回到Azure TTS...");
          // 对所有语言统一使用英文女声
          const voiceName = "en-US-JennyNeural";
          // 转义特殊字符
          const safeText = text.replace(/&/g, "&amp;").replace(/</g, "&lt;").replace(/>/g, "&gt;");
          const ssml =
            "<speak version='1.0' xml:lang='en-US'>" +
            "<voice name='" + voiceName + "'>" +
            safeText +
            "</voice>" +
            "</speak>";

          const resp = await fetch(AZURE_TTS_ENDPOINT, {
            method: "POST",
            headers: {
              "Ocp-Apim-Subscription-Key": AZURE_TTS_KEY,
              "Content-Type": "application/ssml+xml",
              "X-Microsoft-OutputFormat": "audio-16khz-32kbitrate-mono-mp3",
              "User-Agent": "AzureTTSExample"
            },
            body: ssml
          });
          if (!resp.ok) {
            throw new Error("Azure TTS request failed: " + resp.statusText);
          }
          const audioData = await resp.arrayBuffer();
          const blob = new Blob([audioData], { type: "audio/mp3" });

          // 保存TTS Blob用于历史记录
          currentTTSBlob = blob;

          const audioUrl = URL.createObjectURL(blob);

          // 使用已隐藏的 audio 元素播放
          const audioElement = document.getElementById("ttsAudio");
          audioElement.src = audioUrl;
          audioElement.load();

          // 添加更强的错误处理
          audioElement.oncanplay = function () {
            // 应用保存的播放速度
            audioElement.playbackRate = savedPlaybackSpeed;

            // 尝试播放
            const playPromise = audioElement.play();
            if (playPromise !== undefined) {
              playPromise.catch(error => {
                console.error("Azure TTS 播放失败:", error);
                // 尝试再次播放
                setTimeout(() => {
                  audioElement.play().catch(e => console.error("Azure TTS 重试播放仍然失败:", e));
                }, 1000);
              });
            }

            // 播放按钮状态更新
            document.getElementById("playPauseBtn").textContent = "Pause";
          };

          console.log("成功退回到Azure TTS");
        } catch (fallbackErr) {
          console.error("Azure TTS也失败了:", fallbackErr);
        }
      }
    }

    /*************************************************************
     * 5. 播放器控制
     *************************************************************/
    const audioElement = document.getElementById("ttsAudio");
    const playPauseBtn = document.getElementById("playPauseBtn");
    const speedRange = document.getElementById("speedRange");
    const speedValue = document.getElementById("speedValue");
    const progressRange = document.getElementById("progressRange");
    const currentTimeSpan = document.getElementById("currentTime");
    const durationSpan = document.getElementById("duration");

    // 添加错误事件处理
    audioElement.addEventListener("error", (e) => {
      console.error("音频播放错误:", e);
      console.log("错误代码:", audioElement.error ? audioElement.error.code : "未知");
      // 清理当前播放状态
      playPauseBtn.textContent = "Play";
      // 尝试重新加载
      if (audioElement.src) {
        // setTimeout(() => {
        audioElement.load();
        // }, 1000);
      }
    });

    // 添加播放成功事件处理
    audioElement.addEventListener("playing", () => {
      console.log("音频开始播放");
      playPauseBtn.textContent = "Pause";
    });

    playPauseBtn.addEventListener("click", () => {
      if (audioElement.paused) {
        const playPromise = audioElement.play();
        if (playPromise !== undefined) {
          playPromise.catch(error => {
            console.error("播放失败:", error);
            playPauseBtn.textContent = "Play";
          });
        }
      } else {
        audioElement.pause();
        playPauseBtn.textContent = "Play";
      }
    });

    speedRange.addEventListener("input", () => {
      const speed = parseFloat(speedRange.value);
      audioElement.playbackRate = speed;
      speedValue.textContent = speed.toFixed(1) + "x";

      // 保存用户设置的播放速度
      savedPlaybackSpeed = speed;
      localStorage.setItem('savedPlaybackSpeed', speed); // 持久化保存
    });

    // 页面加载时恢复保存的播放速度
    document.addEventListener('DOMContentLoaded', function () {
      const savedSpeed = localStorage.getItem('savedPlaybackSpeed');
      if (savedSpeed) {
        const speed = parseFloat(savedSpeed);
        savedPlaybackSpeed = speed;
        speedRange.value = speed;
        speedValue.textContent = speed.toFixed(1) + "x";
      }
    });

    audioElement.addEventListener("timeupdate", () => {
      if (audioElement.duration) {
        const progress = (audioElement.currentTime / audioElement.duration) * 100;
        progressRange.value = progress;
        currentTimeSpan.textContent = formatTime(audioElement.currentTime);
        durationSpan.textContent = formatTime(audioElement.duration);
      }
    });

    audioElement.addEventListener("loadedmetadata", () => {
      // 音频加载完成后应用保存的播放速度
      audioElement.playbackRate = savedPlaybackSpeed;
    });

    progressRange.addEventListener("input", () => {
      if (audioElement.duration) {
        const seekTime = (progressRange.value / 100) * audioElement.duration;
        audioElement.currentTime = seekTime;
      }
    });

    /*************************************************************
     * 6. Azure STT 实时转写 + OpenAI Whisper 完整音频
     *************************************************************/
    async function getMicStream() {
      // 如果已经获取过流，就不要再请求权限
      if (!micStream) {
        micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
      }
      return micStream;
    }

    async function startRecording() {
      // 停止当前TTS播放
      stopCurrentTTS();

      // 不再清空输入框，允许保留之前的内容
      // inputText.value = "";
      // translatedText.value = "";

      // 不再显示遮罩层，因为我们不再使用它
      // showOverlay();
      // overlayTranscription.value = ""; // 清空遮罩层中的文本

      // 更新录音按钮状态
      recordBtn.innerHTML = '<i class="fas fa-microphone"></i> Recording...';

      // 获得micStream，只会弹一次权限
      getMicStream().then(stream => {
        // 启动Azure连续识别
        recognizer = initAzureRecognizer(stream);
        if (recognizer) {
          recognizer.startContinuousRecognitionAsync();
        }

        // 启动MediaRecorder
        recordChunks = [];
        mediaRecorder = new MediaRecorder(stream);
        mediaRecorder.ondataavailable = (e) => {
          if (e.data.size > 0) {
            recordChunks.push(e.data);
          }
        };
        mediaRecorder.onstop = async () => {
          // 录音停止后 => 发送给Whisper
          const audioBlob = new Blob(recordChunks, { type: "audio/webm" });
          currentAudioBlob = audioBlob; // 保存当前录音
          await sendToWhisper(audioBlob);
        };
        mediaRecorder.start();

        // UI状态
        isRecording = true;
        recordStartTime = Date.now();
        recordTimer = setInterval(() => {
          const elapsed = Math.floor((Date.now() - recordStartTime) / 1000);
          const mm = String(Math.floor(elapsed / 60)).padStart(2, "0");
          const ss = String(elapsed % 60).padStart(2, "0");
          recordBtn.innerHTML = '<i class="fas fa-stop"></i> Stop (' + mm + ":" + ss + ")";
        }, 500);
      }).catch(err => {
        console.error("获取麦克风权限失败:", err);
        alert("无法获取麦克风权限: " + err.message);
        recordBtn.innerHTML = '<i class="fas fa-microphone"></i> Record';
      });
    }

    function stopRecording() {
      if (recognizer) {
        recognizer.stopContinuousRecognitionAsync();
        recognizer = null;
      }

      if (mediaRecorder && mediaRecorder.state !== "inactive") {
        mediaRecorder.stop();
      }

      clearInterval(recordTimer);
      recordTimer = null;
      isRecording = false;
      recordBtn.innerHTML = '<i class="fas fa-microphone"></i> Record';

      // 不再关闭遮罩层，因为我们不再使用它
      // hideOverlay();
    }

    async function sendToWhisper(blob) {
      recordBtn.innerHTML = '<i class="fas fa-cog fa-spin"></i> Processing...';

      try {
        const formData = new FormData();
        formData.append("file", blob, "audio.webm");
        formData.append("model", "whisper-1");

        const resp = await fetch(OPENAI_WHISPER_URL, {
          method: "POST",
          headers: {
            "Authorization": "Bearer " + OPENAI_API_KEY
          },
          body: formData
        });
        if (!resp.ok) {
          throw new Error("Whisper request failed: " + resp.statusText);
        }
        const data = await resp.json();
        const recognizedText = data.text.trim();

        // 清空input text，再显示Whisper的转写结果
        inputText.value = "";

        // 设置Whisper识别结果
        inputText.value = recognizedText;

        // 进行回合制翻译(语言检测 + 翻译 + TTS等)
        await handleInput(recognizedText);

      } catch (err) {
        console.error("Error sending to Whisper:", err);
        alert("Error processing audio: " + err.message);
      } finally {
        recordBtn.innerHTML = '<i class="fas fa-microphone"></i> Record';
      }
    }

    /*************************************************************
     * 7. 绑定UI事件 & 初始化
     *************************************************************/
    document.getElementById("applyManualBtn").addEventListener("click", () => {
      const ml = document.getElementById("manualMainLang").value;
      const tl = document.getElementById("manualTargetLang").value;

      if (ml) {
        mainLanguage = ml;
        userHasManualMain = true;
      }
      if (tl) {
        targetLanguage = tl;
        userHasManualTarget = true;
      }
      updateStatusUI();
    });

    document.getElementById("sendBtn").addEventListener("click", async () => {
      const text = inputText.value.trim();
      if (text) {
        await handleInput(text);
      }
    });

    // 主录音按钮 => 开启/停止
    recordBtn.addEventListener("click", async () => {
      if (!isRecording) {
        // 标记为新的录音会话
        isNewRecordingSession = true;
        recordingSessionId = Date.now();

        // 清空输入和翻译文本
        inputText.value = "";
        translatedText.value = "";

        await startRecording();
      } else {
        stopRecording();

        // 结束当前录音会话
        isNewRecordingSession = false;
        recordingSessionId = null;
      }
    });

    // 日志折叠/展开
    const toggleBtn = document.getElementById("toggleLogBtn");
    const logContainer = document.getElementById("logContainer");
    let isCollapsed = true;
    toggleBtn.addEventListener("click", () => {
      if (!isCollapsed) {
        logContainer.classList.add("log-collapsed");
        toggleBtn.textContent = "Show Log";
        isCollapsed = true;
      } else {
        logContainer.classList.remove("log-collapsed");
        toggleBtn.textContent = "Hide Log";
        isCollapsed = false;
      }
    });

    // 双击清空input
    inputText.addEventListener("dblclick", () => {
      inputText.value = "";
    });

    // 计算音频时长的函数
    async function getAudioDuration(blob) {
      return new Promise((resolve) => {
        const tempAudio = new Audio();
        tempAudio.addEventListener('loadedmetadata', () => {
          resolve(tempAudio.duration);
        });

        // 如果加载失败或无法获取时长，返回未知
        tempAudio.addEventListener('error', () => {
          resolve(null);
        });

        tempAudio.src = URL.createObjectURL(blob);
      });
    }

    // 格式化时长显示
    function formatDuration(seconds) {
      if (!seconds && seconds !== 0) return '';
      const min = Math.floor(seconds / 60);
      const sec = Math.floor(seconds % 60);
      return `(${min}:${sec.toString().padStart(2, '0')})`;
    }

    // 新增函数：流式转录处理 - 使用OpenAI API
    async function streamTranscribe() {
      // 如果已经在进行转写或数据量不足，则退出
      if (streamTranscriptionInProgress || fullPcmDataArray.length < MIN_PCM_DATA_SIZE_FOR_TRANSCRIPTION) {
        return;
      }

      // 防止短时间内重复调用
      const now = Date.now();
      if (now - lastTranscribeTime < TRANSCRIBE_INTERVAL) {
        return;
      }

      try {
        streamTranscriptionInProgress = true;
        lastTranscribeTime = now;

        // 显示转写中状态
        const activeMicBtn = activeMicIndex === 0 ? gmicMicBtn : gmicMicBtn2;
        const currentText = activeMicBtn.innerHTML;
        if (!currentText.includes("转写中")) {
          activeMicBtn.innerHTML = currentText.replace("录音中", "录音中 (转写中)");
        }

        // 创建临时音频数据的副本，避免在处理过程中数据继续增长
        const tempPcmData = new Uint8Array(fullPcmDataArray);

        // 转换PCM数据为WAV格式
        const audioBlob = pcmToWav(tempPcmData, 16000);

        // 创建FormData对象
        const formData = new FormData();
        formData.append("file", audioBlob, "stream_audio.wav");
        // 使用gpt-4o-mini以获得更好的转录质量
        formData.append("model", "gpt-4o-mini-transcribe");

        // 如果已经检测到语言，使用该语言以提高准确性
        if (detectedLanguage) {
          formData.append("language", detectedLanguage);
        }

        // 在输入框中显示"正在转写..."的指示符 - 仅在输入框为空时
        if (!inputText.value) {
          inputText.value = "正在转写...";
        } else if (!inputText.value.endsWith("...") && inputText.value === "正在转写") {
          // 避免重复添加"..."
          inputText.value += "...";
        }

        // 使用超时机制
        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), 10000); // 10秒超时

        // 发送到OpenAI API进行转写
        const response = await fetch(OPENAI_STREAM_TRANSCRIBE_URL, {
          method: "POST",
          headers: {
            "Authorization": "Bearer " + OPENAI_API_KEY
          },
          body: formData,
          signal: controller.signal
        });

        clearTimeout(timeoutId);

        if (!response.ok) {
          throw new Error(`OpenAI转写API返回错误: ${response.status} ${response.statusText}`);
        }

        const result = await response.json();
        console.log("OpenAI转写API返回结果:", result);

        if (result && result.text) {
          // 获取新的转写文本
          const newText = result.text.trim();

          // 如果有新内容，更新转写文本
          if (newText) {
            // 当录音时间超过3秒后，为了避免短语重复，使用新的完整转写替换旧的
            if (Date.now() - bleRecordStartTime > 3000 || !transcribedText) {
              transcribedText = newText;
            }
            // 录音初期，尝试保留已有内容并增量添加
            else if (newText.length > transcribedText.length) {
              transcribedText = newText;
            }

            // 如果未检测语言，尝试从结果中检测
            if (!detectedLanguage && transcribedText.length > 5) {
              try {
                detectedLanguage = await detectLanguageByChatGPT(transcribedText);
                console.log("检测到语言:", detectedLanguage);
              } catch (e) {
                console.error("语言检测失败:", e);
              }
            }

            // 在输入框中显示文本 - 直接更新，不管是否为首次
            if (transcribedText !== "正在转写...") {
              inputText.value = transcribedText;

              // 同时开始翻译处理
              performRealTimeTranslation(transcribedText);

              // 标记已有转写
              window.hasFirstTranscription = true;
            }

            console.log("流式转写更新:", transcribedText);
          }
        }

        // 恢复按钮状态
        if (activeMicBtn.innerHTML.includes("转写中")) {
          const elapsed = Math.floor((Date.now() - bleRecordStartTime) / 1000);
          const mm = String(Math.floor(elapsed / 60)).padStart(2, "0");
          const ss = String(elapsed % 60).padStart(2, "0");
          activeMicBtn.innerHTML = `<i class="fas fa-microphone"></i> GMIC ${activeMicIndex + 1} 录音中 (${mm}:${ss})`;
        }
      } catch (error) {
        console.error("流式转写出错:", error);
        // 出错时也要更新输入框，避免一直显示"正在转写..."
        if (inputText.value === "正在转写..." || inputText.value === "正在转写") {
          inputText.value = "";
        }
      } finally {
        streamTranscriptionInProgress = false;
      }
    }

    // 蓝牙麦克风相关函数
    async function connectGMICMic(micIndex = 0) {
      try {
        const deviceOptions = {
          optionalServices: [
            voiceServiceUUID1,
            voiceServiceUUID2,

            // Standard services
            '0000180f-0000-1000-8000-00805f9b34fb', // Battery service
            '0000180a-0000-1000-8000-00805f9b34fb', // Device info service
            '0000181c-0000-1000-8000-00805f9b34fb', // User data service
            '00001853-0000-1000-8000-00805f9b34fb', // Voice control service
            '00001800-0000-1000-8000-00805f9b34fb', // Generic access
            '00001801-0000-1000-8000-00805f9b34fb', // Generic attribute

            // Common characteristics
            '00002a19-0000-1000-8000-00805f9b34fb', // Battery level characteristic
            '00002a00-0000-1000-8000-00805f9b34fb', // Device name
            '00002a01-0000-1000-8000-00805f9b34fb', // Appearance
            '00002b7a-0000-1000-8000-00805f9b34fb', // Button signal characteristic

            // Try all possible GATT services
            // Use wildcards for unknown GATT services
            '00001800-0000-1000-8000-00805f9b34fb',
            '00001801-0000-1000-8000-00805f9b34fb',
            '00001802-0000-1000-8000-00805f9b34fb',
            '00001803-0000-1000-8000-00805f9b34fb',
            '00001804-0000-1000-8000-00805f9b34fb'
          ],
          filters: [{ namePrefix: "GMIC" }, { namePrefix: "HA" }]
        };

        // 如果已存在设备连接，先断开
        if (bluetoothDevices[micIndex] && bluetoothDevices[micIndex].gatt.connected) {
          console.log(`断开现有设备 ${micIndex + 1} 连接`);
          bluetoothDevices[micIndex].gatt.disconnect();
        }

        resetBluetoothVariables(micIndex);
        console.log(`搜索设备 ${micIndex + 1} 中...`);
        connectTrys = 0;

        // 请求用户选择蓝牙设备
        bluetoothDevices[micIndex] = await navigator.bluetooth.requestDevice(deviceOptions);

        // 🆕 检测重复连接
        const currentDeviceId = bluetoothDevices[micIndex].id;
        const currentDeviceName = bluetoothDevices[micIndex].name;

        // 检查其他索引是否已连接相同设备
        for (let i = 0; i < bluetoothDevices.length; i++) {
          if (i !== micIndex && bluetoothDevices[i] && bluetoothDevices[i].id === currentDeviceId) {
            alert("检测到重复连接，请重新选择设备");
            console.warn(`⚠️ 检测到重复连接: 设备 "${currentDeviceName}" (ID: ${currentDeviceId}) 已连接到麦克风${i + 1}`);

            // 清除当前连接尝试，保持原有设备不变
            bluetoothDevices[micIndex] = null;

            // 更新UI状态为未连接
            const micBtn = micIndex === 0 ? gmicMicBtn : gmicMicBtn2;
            micBtn.classList.remove('connecting', 'connected');
            micBtn.innerHTML = `<i class="fas fa-bluetooth"></i> GMIC-MIC0${micIndex + 1}`;

            return; // 退出连接流程
          }
        }

        console.log(`[调试] 设备信息:`, {
          name: bluetoothDevices[micIndex].name,
          id: bluetoothDevices[micIndex].id,
          connected: bluetoothDevices[micIndex].gatt.connected
        });

        // 添加断开连接的事件监听
        bluetoothDevices[micIndex].addEventListener('gattserverdisconnected', () => handleDisconnection(micIndex));
        console.log(`连接设备 ${micIndex + 1}: ${bluetoothDevices[micIndex].name}`);

        // 连接GATT服务器并设置服务
        await doConnect(voiceServiceUUID1, micIndex);

        // 更新UI显示连接成功
        const micBtn = micIndex === 0 ? gmicMicBtn : gmicMicBtn2;
        micBtn.classList.remove('connecting');
        micBtn.classList.add('connected');
        micBtn.innerHTML = `<i class="fas fa-bluetooth"></i> Connected ${micIndex + 1}`;

      } catch (error) {
        console.error(`Bluetooth Error (Mic ${micIndex + 1}):`, error);
        const micBtn = micIndex === 0 ? gmicMicBtn : gmicMicBtn2;
        micBtn.classList.remove('connecting', 'connected');
        micBtn.innerHTML = `<i class="fas fa-bluetooth"></i> GMIC-MIC0${micIndex + 1}`;

        // 显示更友好的错误消息
        if (error.message.includes("GATT Server is disconnected")) {
          alert(`无法连接麦克风 ${micIndex + 1}：蓝牙连接断开。请尝试重新配对设备或重启麦克风。`);
        } else if (error.message.includes("User cancelled")) {
          console.log("用户取消了设备选择");
        } else {
          alert(`连接麦克风 ${micIndex + 1} 失败: ${error.message}`);
        }

        bluetoothDevices[micIndex] = null;
      }
    }

    async function doConnect(currentUUID, micIndex) {
      try {
        console.log(`连接 GATT (Mic ${micIndex + 1})...`);

        // 确保设备存在且未连接
        if (!bluetoothDevices[micIndex]) {
          throw new Error("设备未初始化");
        }

        // 建立GATT连接
        gattServers[micIndex] = await bluetoothDevices[micIndex].gatt.connect();
        console.log(`已连接到 GATT 服务器 (Mic ${micIndex + 1})`);

        // 尝试设置服务
        try {
          await setupServices(currentUUID, micIndex);
        } catch (e) {
          console.error(`设置服务失败 (Mic ${micIndex + 1}):`, e);

          // 如果第一个UUID失败，尝试第二个
          if (currentUUID === voiceServiceUUID1) {
            console.log(`UUID1 失败, 尝试 UUID2 (Mic ${micIndex + 1})...`);
            await setupServices(voiceServiceUUID2, micIndex);
          } else {
            throw e;
          }
        }
      } catch (error) {
        console.error(`GATT连接失败 (Mic ${micIndex + 1}):`, error);

        // 如果错误是GATT服务器断开，尝试重新连接
        if (error.message.includes("GATT Server is disconnected")) {
          // 最多尝试重连3次
          if (connectTrys < 3) {
            connectTrys++;
            console.log(`尝试重新连接 (尝试 ${connectTrys}/3)...`);

            // 等待1秒后重试
            await new Promise(resolve => setTimeout(resolve, 1000));
            return await doConnect(currentUUID, micIndex);
          }
        }
        throw error;
      }
    }

    async function setupServices(uuid, micIndex) {
      try {
        // 检查GATT服务器是否已连接
        if (!gattServers[micIndex] || !gattServers[micIndex].connected) {
          console.log("GATT服务器未连接，重新连接中...");
          gattServers[micIndex] = await bluetoothDevices[micIndex].gatt.connect();
        }

        // 获取所有服务以进行调试
        console.log(`[蓝牙调试] 获取设备 ${micIndex + 1} 的所有服务...`);
        const allServices = await gattServers[micIndex].getPrimaryServices();
        console.log(`[蓝牙调试] 找到 ${allServices.length} 个服务:`);

        // 遍历每个服务
        for (const service of allServices) {
          console.log(`\n[服务] UUID: ${service.uuid}`);

          // 获取每个服务的特征值
          const characteristics = await service.getCharacteristics();
          console.log(`[特征值] 服务 ${service.uuid} 包含 ${characteristics.length} 个特征值:`);

          // 遍历每个特征值
          for (const char of characteristics) {
            console.log(`\n[特征值详情]:`, {
              UUID: char.uuid,
              属性: {
                broadcast: char.properties.broadcast,
                read: char.properties.read,
                writeWithoutResponse: char.properties.writeWithoutResponse,
                write: char.properties.write,
                notify: char.properties.notify,
                indicate: char.properties.indicate,
                authenticatedSignedWrites: char.properties.authenticatedSignedWrites,
                reliableWrite: char.properties.reliableWrite,
                writableAuxiliaries: char.properties.writableAuxiliaries
              }
            });

            // 如果特征值支持读取，尝试读取当前值
            if (char.properties.read) {
              try {
                const value = await char.readValue();
                console.log(`[特征值读取]:`, {
                  UUID: char.uuid,
                  值: Array.from(new Uint8Array(value.buffer)).map(b => '0x' + b.toString(16).padStart(2, '0')).join(' '),
                  ASCII: Array.from(new Uint8Array(value.buffer)).map(b => b >= 32 && b <= 126 ? String.fromCharCode(b) : '.').join('')
                });
              } catch (e) {
                console.log(`[特征值读取失败] UUID ${char.uuid}:`, e);
              }
            }

            // 如果特征值支持通知，尝试监听
            if (char.properties.notify) {
              try {
                // 添加延迟，防止GATT操作过快导致失败
                await new Promise(resolve => setTimeout(resolve, 300));

                await char.startNotifications();
                char.addEventListener('characteristicvaluechanged', async (event) => {
                  const value = new Uint8Array(event.target.value.buffer);
                  // console.log(`[特征值通知] UUID ${char.uuid}:`, {
                  //   数据: Array.from(value).map(b => '0x' + b.toString(16).padStart(2, '0')).join(' '),
                  //   ASCII: Array.from(value).map(b => b >= 32 && b <= 126 ? String.fromCharCode(b) : '.').join(''),
                  //   时间戳: new Date().toISOString()
                  // });
                });
                console.log(`[特征值] UUID ${char.uuid} 通知已启动`);
              } catch (e) {
                console.log(`[特征值通知启动失败] UUID ${char.uuid}:`, e);
                // 继续执行，不中断整个流程
              }
            }
          }
        }

        // 继续原有的服务设置逻辑
        console.log(`\n[设置服务] 尝试查找主服务 (Mic ${micIndex + 1}): ${uuid}`);
        voiceServices[micIndex] = await gattServers[micIndex].getPrimaryService(uuid);
        console.log(`[设置服务] 找到语音服务 (Mic ${micIndex + 1}): ${uuid}`);

        // 先设置语音数据特征值
        console.log(`尝试查找语音数据特征值 (Mic ${micIndex + 1}): ${voiceDataCharacteristicUUID}`);
        voiceDataCharacteristics[micIndex] = await voiceServices[micIndex].getCharacteristic(voiceDataCharacteristicUUID);
        console.log(`找到语音数据特征值 (Mic ${micIndex + 1}), 属性:`, voiceDataCharacteristics[micIndex].properties);

        // 添加事件监听器
        const onVoiceDataChanged = async (event) => {
          await handleVoiceData(event);
        };

        // 先尝试移除旧的监听器（如果存在）
        try {
          voiceDataCharacteristics[micIndex].removeEventListener('characteristicvaluechanged', onVoiceDataChanged);
        } catch (e) {
          console.log("无需移除旧监听器");
        }

        // 添加新的监听器
        voiceDataCharacteristics[micIndex].addEventListener('characteristicvaluechanged', onVoiceDataChanged);
        console.log("已添加语音数据监听器");

        // 启动通知前先等待一小段时间，增加延迟以提高成功率
        await new Promise(resolve => setTimeout(resolve, 500));

        try {
          // 启动语音数据通知
          await voiceDataCharacteristics[micIndex].startNotifications();
          console.log(`语音数据通知已启动 (Mic ${micIndex + 1})`);
        } catch (e) {
          console.warn(`语音数据通知启动警告: ${e}, 继续执行...`);
          // 继续执行，不中断连接流程
        }

        // 设置按钮控制特征值
        console.log(`尝试查找按钮特征值 (Mic ${micIndex + 1}): ${buttonCharacteristicUUID}`);
        const buttonCharacteristic = await voiceServices[micIndex].getCharacteristic(buttonCharacteristicUUID);
        console.log('找到按钮信号特征值:', {
          uuid: buttonCharacteristic.uuid,
          properties: buttonCharacteristic.properties
        });

        // 启动按钮通知前先等待一小段时间
        await new Promise(resolve => setTimeout(resolve, 500));

        // 启动按钮通知
        let isFirstSignal = true;  // 用于跟踪是第一个还是第二个信号
        try {
          await buttonCharacteristic.startNotifications();
          console.log(`按钮通知已成功启动 (Mic ${micIndex + 1})`);
        } catch (e) {
          console.warn(`按钮通知启动警告: ${e}, 继续执行...`);
          // 继续执行，不中断连接流程
        }

        buttonCharacteristic.addEventListener('characteristicvaluechanged', async (event) => {
          const value = new Uint8Array(event.target.value.buffer);
          console.log(`[按钮信号] 收到信号:`, {
            数据: Array.from(value).map(b => '0x' + b.toString(16).padStart(2, '0')).join(' '),
            信号次数: isFirstSignal ? '第一次' : '第二次',
            时间戳: new Date().toISOString()
          });

          if (isFirstSignal) {
            // 第一次信号 - 开始录音
            console.log('[按钮事件] 收到第一次信号，开始录音');
            if (!isBluetoothRecording) {
              // 停止当前TTS播放
              stopCurrentTTS();

              // 标记为新的录音会话
              isNewRecordingSession = true;
              recordingSessionId = Date.now();

              // 清空所有文本状态
              accumulatedText = "";
              currentPartialText = "";
              inputText.value = "";
              translatedText.value = "";

              // 重置录音状态
              resetRecordingState(true); // true表示清空input
              activeMicIndex = micIndex; // 设置当前活动麦克风

              // 开始录音
              startBluetoothRecording();
            }
          } else {
            // 第二次信号 - 停止录音
            console.log('[按钮事件] 收到第二次信号，停止录音');
            if (isBluetoothRecording && activeMicIndex === micIndex) {
              // 设置按钮触发标志，防止超时检查
              buttonTriggeredStop = true;

              // 立即停止所有计时器
              stopRecordingTimers();

              // 清除数据检查定时器
              if (checkDataTimeoutInterval) {
                clearInterval(checkDataTimeoutInterval);
                checkDataTimeoutInterval = null;
              }

              // 清除流式转写定时器
              if (streamTranscribeTimeoutId) {
                clearTimeout(streamTranscribeTimeoutId);
                streamTranscribeTimeoutId = null;
              }

              // 先设置状态防止其他处理
              isBluetoothRecording = false;

              // 立即更新UI状态，防止用户混淆
              const micBtn = activeMicIndex === 0 ? gmicMicBtn : gmicMicBtn2;
              micBtn.classList.remove('recording');
              micBtn.classList.add('waiting');
              micBtn.innerHTML = `<i class="fas fa-cog fa-spin"></i> 处理中...`;

              // 停止Azure识别器
              if (bleRecognizer) {
                try {
                  await stopAzureRecognizer();
                } catch (e) {
                  console.error('停止Azure识别器时出错:', e);
                }
              }

              // 处理录音数据
              if (fullPcmDataArray.length > 1000) {
                isProcessingData = true;
                processingStartTime = Date.now();

                try {
                  await processPcmData(true);

                  // 处理完成后，确保UI更新为就绪状态
                  micBtn.innerHTML = `<i class="fas fa-microphone"></i> GMIC ${micIndex + 1} Ready`;
                } catch (error) {
                  console.error('处理录音数据时出错:', error);
                  // 即使处理失败，也要确保UI恢复正常
                  micBtn.innerHTML = `<i class="fas fa-microphone"></i> GMIC ${micIndex + 1} Ready`;
                }
              } else {
                // 即使没有足够数据处理，也要确保UI恢复正常
                micBtn.innerHTML = `<i class="fas fa-microphone"></i> GMIC ${micIndex + 1} Ready`;
              }

              // 结束当前录音会话
              isNewRecordingSession = false;
              recordingSessionId = null;
              buttonTriggeredStop = false;
            }
          }

          // 切换信号标志
          isFirstSignal = !isFirstSignal;
        });

        console.log(`按钮信号通知已启动 (Mic ${micIndex + 1})`);

        // 写入初始状态 (0 = 语音结束)
        try {
          await buttonCharacteristic.writeValueWithoutResponse(new Uint8Array([0]));
          console.log('[按钮控制] 已写入初始状态: 语音结束');

          // 保存按钮特征值引用，用于后续控制
          window[`buttonCharacteristic_${micIndex}`] = buttonCharacteristic;

          // 更新UI状态
          const micBtn = micIndex === 0 ? gmicMicBtn : gmicMicBtn2;
          micBtn.classList.remove('connecting');
          micBtn.classList.add('waiting');
          micBtn.innerHTML = `<i class="fas fa-microphone"></i> GMIC ${micIndex + 1} Ready`;

          console.log(`设备 ${micIndex + 1} 设置完成，可以使用`);
          return true;
        } catch (writeError) {
          console.error('写入按钮状态失败:', writeError);
          throw writeError;
        }

      } catch (error) {
        console.error(`[蓝牙错误] 设置服务失败 (Mic ${micIndex + 1}):`, error);
        throw error;
      }
    }

    // 处理蓝牙断开连接
    function handleDisconnection(micIndex) {
      console.log(`Bluetooth device ${micIndex + 1} disconnected`);

      if (activeMicIndex === micIndex) {
        isBluetoothRecording = false;
        isProcessingData = false; // 确保处理状态被重置
      }

      const micBtn = micIndex === 0 ? gmicMicBtn : gmicMicBtn2;
      micBtn.classList.remove('connecting', 'waiting', 'recording', 'connected');
      micBtn.innerHTML = `<i class="fas fa-bluetooth"></i> GMIC-MIC0${micIndex + 1}`;

      resetBluetoothVariables(micIndex);

      // 在断开连接5秒后尝试自动重连
      setTimeout(() => {
        // 只有在用户未手动重连的情况下尝试自动重连
        if (!bluetoothDevices[micIndex] || !bluetoothDevices[micIndex].gatt.connected) {
          console.log(`尝试自动重连设备 ${micIndex + 1}...`);
          // 此处不直接调用connectGMICMic因为它会弹出设备选择对话框
          // 相反，如果设备引用仍然存在，尝试直接重连
          if (bluetoothDevices[micIndex]) {
            tryReconnect(micIndex);
          }
        }
      }, 5000);
    }

    // 新增：尝试重新连接设备的函数
    async function tryReconnect(micIndex) {
      const micBtn = micIndex === 0 ? gmicMicBtn : gmicMicBtn2;
      micBtn.classList.add('connecting');
      micBtn.innerHTML = `<i class="fas fa-sync fa-spin"></i> 正在重连...`;

      try {
        if (bluetoothDevices[micIndex]) {
          console.log(`尝试重连设备 ${micIndex + 1}`);
          gattServers[micIndex] = await bluetoothDevices[micIndex].gatt.connect();
          console.log(`重连成功, 设置服务 (Mic ${micIndex + 1})`);

          // 重新设置服务
          await setupServices(voiceServiceUUID, micIndex);

          console.log(`设备 ${micIndex + 1} 重连成功`);
          micBtn.classList.remove('connecting');
          micBtn.classList.add('connected');
          micBtn.innerHTML = `<i class="fas fa-bluetooth"></i> 已重连 ${micIndex + 1}`;
        } else {
          throw new Error("设备引用已丢失，无法重连");
        }
      } catch (error) {
        console.error(`重连失败 (Mic ${micIndex + 1}):`, error);
        micBtn.classList.remove('connecting', 'connected');
        micBtn.innerHTML = `<i class="fas fa-bluetooth"></i> GMIC-MIC0${micIndex + 1}`;
      }
    }

    // 重置蓝牙变量
    function resetBluetoothVariables(micIndex = -1) {
      if (micIndex >= 0) {
        // 重置特定麦克风
        bluetoothDevices[micIndex] = null;
        gattServers[micIndex] = null;
        voiceServices[micIndex] = null;
        voiceDataCharacteristics[micIndex] = null;
      } else {
        // 重置所有麦克风
        bluetoothDevices = [null, null];
        gattServers = [null, null];
        voiceServices = [null, null];
        voiceDataCharacteristics = [null, null];
        fullPcmDataArray = [];
        isProcessingData = false;
      }
    }

    // 修改startBluetoothRecording函数 - 适配多麦克风
    function startBluetoothRecording() {
      console.log("开始蓝牙录音...");

      // 停止当前TTS播放
      stopCurrentTTS();

      // 防止重复启动
      if (isBluetoothRecording && !isProcessingData) {
        console.log("已经在录音中，忽略此次启动请求");
        isRecognizerInitializing = false; // 重置初始化标志
        return;
      }

      // 只有在新会话时才清空文本
      if (isNewRecordingSession) {
        console.log("新录音会话，清空文本");
        inputText.value = "";
        translatedText.value = "";
        accumulatedText = "";
        currentPartialText = "";
      } else {
        console.log("继续现有会话，保留文本");
      }

      // 重置录音状态变量 - 更彻底地清理所有状态
      isBluetoothRecording = true;
      fullPcmDataArray = [];
      lastDataReceivedTime = Date.now();
      lastTranscribeTime = 0;
      streamTranscriptionInProgress = false;

      // 只在新会话时重置transcribedText
      if (isNewRecordingSession) {
        transcribedText = "";
      }

      // 重置实时转写首次接收标志
      window.hasFirstTranscription = false;

      // 启动录音时长计时器
      bleRecordStartTime = Date.now();
      if (bleRecordTimer) {
        clearInterval(bleRecordTimer);
      }
      bleRecordTimer = setInterval(updateBleRecordingTime, 500);

      // 更新UI状态
      const activeMicBtn = activeMicIndex === 0 ? gmicMicBtn : gmicMicBtn2;
      activeMicBtn.classList.remove('waiting');
      activeMicBtn.classList.add('recording');
      activeMicBtn.innerHTML = '<i class="fas fa-microphone"></i> GMIC 录音中... (00:00)';

      // 启动数据检查定时器
      if (checkDataTimeoutInterval) {
        clearInterval(checkDataTimeoutInterval);
      }
      checkDataTimeoutInterval = setInterval(checkDataTimeout, 500);

      // 启动Azure识别 - 确保识别器是活跃的
      if (!bleRecognizer || azureConnectionFailed) {
        console.log("初始化Azure语音识别器...");
        bleRecognizer = initBLERecognizer();

        if (bleRecognizer) {
          // 启动识别
          console.log("启动新创建的Azure识别器...");
          startBLEAzureRecognition();
        } else {
          console.warn("无法初始化Azure识别器，将只使用Whisper进行流式转写");
        }
      } else {
        // 检查识别器状态并确保其正在运行
        try {
          // 尝试重新启动识别
          console.log("尝试确保Azure识别器正在运行...");
          // 清理旧的recognizer连接
          bleRecognizer.stopContinuousRecognitionAsync(
            () => {
              console.log("已停止旧的识别器");
              // 重新启动
              startBLEAzureRecognition();
            },
            (err) => {
              console.warn("停止旧识别器失败:", err);
              // 仍然尝试启动
              startBLEAzureRecognition();
            }
          );
        } catch (e) {
          console.error("操作Azure识别器失败:", e);
          // 重置并重新创建
          try {
            if (bleRecognizer) {
              bleRecognizer.close();
            }
          } catch (e2) { }

          bleRecognizer = initBLERecognizer();
          if (bleRecognizer) {
            startBLEAzureRecognition();
          }
        }
      }
    }

    // 更新录音时长显示的函数
    function updateBleRecordingTime() {
      if (!bleRecordStartTime || !isBluetoothRecording || activeMicIndex < 0) return;

      const elapsed = Math.floor((Date.now() - bleRecordStartTime) / 1000);
      const mm = String(Math.floor(elapsed / 60)).padStart(2, "0");
      const ss = String(elapsed % 60).padStart(2, "0");

      // 更新当前活动麦克风录音按钮显示时长
      const activeMicBtn = activeMicIndex === 0 ? gmicMicBtn : gmicMicBtn2;

      if (activeMicBtn.innerHTML.includes("GMIC")) {
        activeMicBtn.innerHTML = `<i class="fas fa-microphone"></i> GMIC ${activeMicIndex + 1} 录音中 (${mm}:${ss})`;
      }
    }

    // 停止Azure识别器
    async function stopAzureRecognizer() {
      console.log("停止Azure识别器...");

      // 状态标记
      const stopStartTime = Date.now();
      let isStopped = false;

      // 创建一个超时保护
      const timeoutPromise = new Promise((resolve) => {
        setTimeout(() => {
          if (!isStopped) {
            console.warn("停止Azure识别器超时 - 强制清理");
            resolve(false);
          }
        }, 5000); // 5秒超时
      });

      // 实际停止操作
      const stopPromise = new Promise((resolve) => {
        try {
          if (bleRecognizer) {
            // 尝试关闭WebSocket连接
            bleRecognizer.stopContinuousRecognitionAsync(
              () => {
                console.log("Azure识别器停止成功 - 耗时：", Date.now() - stopStartTime, "ms");
                isStopped = true;
                resolve(true);
              },
              (error) => {
                console.error("Azure识别器停止失败:", error);
                resolve(false);
              }
            );
          } else {
            console.log("Azure识别器已为空，无需停止");
            isStopped = true;
            resolve(true);
          }
        } catch (e) {
          console.error("停止Azure识别器时发生异常:", e);
          resolve(false);
        }
      });

      // 等待停止完成或超时
      const result = await Promise.race([stopPromise, timeoutPromise]);

      // 不管是否超时，都进行资源清理
      try {
        // 强制清理连接
        forceCleanupWebSockets();

        // 明确设置为null确保GC回收
        if (bleRecognizer) {
          try {
            bleRecognizer.close();
          } catch (e) {
            console.error("关闭Azure识别器时出错:", e);
          }
          bleRecognizer = null;
        }

        // 重置关键状态变量，确保无论如何都更新UI状态
        isBluetoothRecording = false;
        isProcessingData = false;
        isRecognizerInitializing = false;

        console.log("Azure识别器资源已清理");
      } catch (e) {
        console.error("清理Azure识别器资源时出错:", e);
      }

      return result;
    }

    // 重置录音状态，确保所有资源正确释放
    async function resetRecordingState(clearInputText = true) {
      console.log("重置录音状态...");

      // 重置按钮触发标志
      buttonTriggeredStop = false;

      // 重置连接状态
      connectionEstablished = false;
      recognizerInitComplete = false;

      // 重置数据缓冲区
      if (typeof pendingDataBuffer !== 'undefined') {
        pendingDataBuffer = [];
      }

      // 重置麦克风状态
      isRecording = false;
      recordingStartTime = 0;
      startButtonClicked = false;
      recordingDuration = 0;
      recordingInterval = null;

      // 重置录音相关变量
      recordedChunks = [];
      activeRecorder = null;
      actualSampleRate = 0;

      // 等待短暂时间确保资源释放
      await new Promise(resolve => setTimeout(resolve, 500));

      console.log("录音状态已完全重置，所有变量已清理");
      return true;
    }

    // 修改发送缓冲区数据的相关代码
    function sendPendingBufferData(recognizer) {
      if (!recognizer || !recognizer.pushStream) return false;

      let successCount = 0;
      let failCount = 0;

      console.log(`准备发送缓冲数据(${pendingDataBuffer.length}个)...`);

      // 逐个发送缓冲区数据
      while (pendingDataBuffer.length > 0) {
        const bufferData = pendingDataBuffer.shift();

        // 安全检查
        if (!bufferData) {
          console.warn("跳过无效的缓冲数据");
          failCount++;
          continue;
        }

        try {
          // 尝试创建数据副本发送
          const dataView = new Int16Array(bufferData);
          const bufferCopy = dataView.slice().buffer;

          if (recognizer.pushStream.write(bufferCopy)) {
            successCount++;
          } else {
            failCount++;
          }
        } catch (e) {
          console.log("发送缓冲数据失败:", e);
          failCount++;
          break;
        }
      }

      console.log(`缓冲数据发送结果: 成功=${successCount}, 失败=${failCount}`);
      return successCount > 0;
    }

    // 修改recognizer.recognizing回调中发送缓冲区数据的部分
    // 在initBLERecognizer函数中
    // 更新下面这段代码:
    /*
    // 收到数据后停用缓冲机制
    if (dataBufferEnabled && pendingDataBuffer.length > 0) {
      console.log(`收到转写结果，发送缓冲区数据(${pendingDataBuffer.length}个)`);
      dataBufferEnabled = false;
      
      // 发送缓冲的数据
      while (pendingDataBuffer.length > 0) {
        const bufferData = pendingDataBuffer.shift();
        try {
          recognizer.pushStream.write(bufferData);
        } catch (e) {
          console.log("发送缓冲数据失败，忽略");
          break;
        }
      }
    }
    */
    // 替换为:
    /*
    // 收到数据后停用缓冲机制
    if (dataBufferEnabled && pendingDataBuffer.length > 0) {
      console.log(`收到转写结果，发送缓冲区数据(${pendingDataBuffer.length}个)`);
      dataBufferEnabled = false;
      
      // 使用安全的发送函数
      sendPendingBufferData(recognizer);
    }
    */

    // 修改connectionOpened事件处理中的发送缓冲区数据部分
    // 在initBLERecognizer函数中
    // 更新下面这段代码:
    /*
    // 连接建立后，在短暂延迟后发送缓冲的数据
    setTimeout(() => {
      if (dataBufferEnabled && pendingDataBuffer.length > 0) {
        console.log(`连接建立，发送缓冲区数据(${pendingDataBuffer.length}个)`);
        
        // 发送缓冲的数据
        while (pendingDataBuffer.length > 0) {
          const bufferData = pendingDataBuffer.shift();
          try {
            recognizer.pushStream.write(bufferData);
          } catch (e) {
            console.log("发送缓冲数据失败，忽略");
            break;
          }
        }
      }
    }, 500); // 延迟500ms确保连接完全就绪
    */
    // 替换为:
    /*
    // 连接建立后，在短暂延迟后发送缓冲的数据
    setTimeout(() => {
      if (dataBufferEnabled && pendingDataBuffer.length > 0) {
        console.log(`连接建立，发送缓冲区数据(${pendingDataBuffer.length}个)`);
        
        // 使用安全的发送函数
        sendPendingBufferData(recognizer);
      }
    }, 500); // 延迟500ms确保连接完全就绪
    */

    // 添加常量定义
    const RECONNECT_DELAY = 2500; // 重连延迟时间 (毫秒)
    const DIFFERENT_SESSIONS_DELAY = 5000; // 不同会话间的冷却时间 (毫秒)
    let lastSpeechServiceUseTime = 0; // 上次使用语音服务的时间

    // 强制清理WebSocket连接的函数
    function forceCleanupWebSockets() {
      console.log("强制清理WebSocket连接...");

      // 尝试关闭全局SpeechSDK连接
      if (window.SpeechSDK && window.SpeechSDK.Connection) {
        try {
          // 尝试查找可能的连接清理方法
          const connectionModule = window.SpeechSDK.Connection;

          // 尝试不同可能的方法名
          if (typeof connectionModule.closeAll === 'function') {
            connectionModule.closeAll();
            console.log("已执行SpeechSDK.Connection.closeAll()");
          }

          if (typeof connectionModule.closeConnection === 'function') {
            connectionModule.closeConnection();
            console.log("已执行SpeechSDK.Connection.closeConnection()");
          }
        } catch (e) {
          console.warn("尝试关闭SpeechSDK连接时出错:", e);
        }
      }

      // 尝试关闭所有可能活动的WebSocket
      try {
        if (window.speechsdk && window.speechsdk.CognitiveSubscriptionKeyAuthentication) {
          console.log("清理speechsdk认证状态");
          window.speechsdk.CognitiveSubscriptionKeyAuthentication = null;
        }
      } catch (e) {
        console.warn("清理speechsdk认证状态时出错:", e);
      }

      // 重置所有连接相关状态
      connectionEstablished = false;
      recognizerInitComplete = false;
      azureConnectionFailed = false;
      connectionRetryCount = 0;

      console.log("WebSocket连接清理完成");
    }

    // 修改createAndStartNewRecognizer函数，添加会话间冷却期
    async function createAndStartNewRecognizer() {
      try {
        // 检查是否需要等待冷却期
        const now = Date.now();
        const timeSinceLastUse = now - lastSpeechServiceUseTime;

        if (lastSpeechServiceUseTime > 0 && timeSinceLastUse < DIFFERENT_SESSIONS_DELAY) {
          // 需要等待完成冷却期
          const waitTime = DIFFERENT_SESSIONS_DELAY - timeSinceLastUse;
          console.log(`等待语音服务冷却期 ${waitTime}ms...`);
          await new Promise(resolve => setTimeout(resolve, waitTime));
        }

        // 强制清理WebSocket连接
        forceCleanupWebSockets();

        // 确保旧实例已完全停止
        if (bleRecognizer) {
          console.log("停止旧识别器并进行清理");
          try {
            await stopAzureRecognizer();
          } catch (e) {
            console.error("停止旧识别器时出错:", e);
          }
          // 额外冷却时间
          await new Promise(resolve => setTimeout(resolve, RECONNECT_DELAY));
        } else {
          console.log("无旧识别器，直接创建新识别器");
        }

        // 初始化新识别器 - 使用默认区域
        console.log("初始化新识别器...");
        bleRecognizer = initBLERecognizer();
        if (!bleRecognizer) {
          console.error("识别器初始化失败");
          azureConnectionFailed = true;
          return null;
        }

        // 更新最后使用时间
        lastSpeechServiceUseTime = Date.now();

        // 启动连续识别
        console.log("启动语音识别...");
        return new Promise((resolve, reject) => {
          bleRecognizer.startContinuousRecognitionAsync(
            () => {
              console.log("Azure识别器启动成功");
              resolve(bleRecognizer);
            },
            (error) => {
              console.error("Azure识别器启动失败:", error);
              azureConnectionFailed = true;
              reject(error);
            }
          );
        });
      } catch (error) {
        console.error("创建识别器时出错:", error);
        azureConnectionFailed = true;
        return null;
      }
    }

    // 解码ADPCM数据为PCM 并返回 Int16Array
    function decodeADPCM(adpcmData) {
      // 确保adpcmData是数组格式
      const adpcmArray = Array.from(adpcmData);

      // 先解码到PCM数组
      let pcmData = [];
      adpcmToPcm(adpcmArray, pcmData);

      // 创建Int16Array用于Azure识别器
      const pcmInt16 = new Int16Array(pcmData.length / 2);
      for (let i = 0; i < pcmData.length; i += 2) {
        // 注意：这里需要使用小端序格式
        pcmInt16[i / 2] = (pcmData[i + 1] << 8) | pcmData[i];
      }

      return pcmInt16;
    }


    // 创建Azure实时转写状态元素
    const azureStatus = document.createElement("div");
    azureStatus.id = "azureStatus";
    azureStatus.style.display = "none";
    azureStatus.style.fontFamily = "Microsoft YaHei, 微软雅黑, sans-serif";
    azureStatus.style.padding = "5px";
    azureStatus.style.margin = "5px 0";
    azureStatus.style.borderRadius = "4px";
    azureStatus.style.backgroundColor = "#f0f0f0";
    azureStatus.style.fontSize = "1rem";
    azureStatus.style.maxWidth = "100%";
    azureStatus.textContent = "准备接收实时转写...";

    // 添加到页面
    document.querySelector(".container").insertBefore(azureStatus, document.querySelector(".text-columns"));

    // 显示Azure实时转写结果的函数
    function showAzureTranscription(text) {
      if (!text || text.trim() === "") return;

      // 更新状态显示
      azureStatus.textContent = text;

      // 更新输入框文本 - 始终更新以显示最新内容
      inputText.value = text;
      inputText.scrollTop = inputText.scrollHeight;

      // 实时翻译文本
      performRealTimeTranslation(text);

      // 如果是首次收到结果，标记已收到
      if (!window.hasFirstTranscription) {
        window.hasFirstTranscription = true;
      }

      // 记录连接状态正常
      azureConnectionFailed = false;
    }

    // 修改绑定蓝牙麦克风按钮事件
    gmicMicBtn.addEventListener('click', async () => {
      handleMicButtonClick(0);
    });

    gmicMicBtn2.addEventListener('click', async () => {
      handleMicButtonClick(1);
    });

    // 统一处理麦克风按钮点击事件
    async function handleMicButtonClick(micIndex) {
      if (!bluetoothDevices[micIndex] || !bluetoothDevices[micIndex].gatt.connected) {
        // 如果未连接，尝试连接设备
        const micBtn = micIndex === 0 ? gmicMicBtn : gmicMicBtn2;
        micBtn.classList.add('connecting');
        micBtn.textContent = `Connecting Mic ${micIndex + 1}...`;
        await connectGMICMic(micIndex);
      } else {
        // 如果已连接，点击按钮开始/停止录音
        if (!isBluetoothRecording && !isRecognizerInitializing && !isProcessingData) {
          try {
            buttonTriggeredStop = false;  // 重置标志
            // 获取按钮特征值引用
            const buttonCharacteristic = window[`buttonCharacteristic_${micIndex}`];
            if (buttonCharacteristic) {
              // 写入开始录音命令 (1)
              await buttonCharacteristic.writeValueWithoutResponse(new Uint8Array([1]));
              console.log('[按钮控制] 已发送开始录音命令');
            }

            // 标记为新的录音会话
            isNewRecordingSession = true;
            recordingSessionId = Date.now();

            // 清空输入和输出文本
            inputText.value = "";
            translatedText.value = "";

            // 完全重置状态后开始录音
            resetRecordingState(true);
            // 设置当前活动麦克风
            activeMicIndex = micIndex;
            // 开始录音
            startBluetoothRecording();
          } catch (error) {
            console.error('发送开始录音命令失败:', error);
          }
        } else if (isBluetoothRecording && !isProcessingData && activeMicIndex === micIndex) {
          try {
            // 设置按钮触发标志
            buttonTriggeredStop = true;
            console.log("按钮触发停止录音");

            // 获取按钮特征值引用
            const buttonCharacteristic = window[`buttonCharacteristic_${micIndex}`];
            if (buttonCharacteristic) {
              // 写入停止录音命令 (0)
              await buttonCharacteristic.writeValueWithoutResponse(new Uint8Array([0]));
              console.log('[按钮控制] 已发送停止录音命令');
            }

            // 立即停止所有计时器
            stopRecordingTimers();

            // 清除数据检查定时器
            if (checkDataTimeoutInterval) {
              clearInterval(checkDataTimeoutInterval);
              checkDataTimeoutInterval = null;
            }

            // 清除流式转写定时器
            if (streamTranscribeTimeoutId) {
              clearTimeout(streamTranscribeTimeoutId);
              streamTranscribeTimeoutId = null;
            }

            // 先设置状态防止其他处理
            isBluetoothRecording = false;

            // 立即更新UI状态，防止用户混淆
            const micBtn = activeMicIndex === 0 ? gmicMicBtn : gmicMicBtn2;
            micBtn.classList.remove('recording');
            micBtn.classList.add('waiting');
            micBtn.innerHTML = `<i class="fas fa-cog fa-spin"></i> 处理中...`;

            // 停止Azure识别器
            if (bleRecognizer) {
              try {
                await stopAzureRecognizer();
              } catch (e) {
                console.error('停止Azure识别器时出错:', e);
              }
            }

            // 处理录音数据
            if (fullPcmDataArray.length > 1000) {
              isProcessingData = true;
              processingStartTime = Date.now();

              try {
                await processPcmData(true);

                // 处理完成后，确保UI更新为就绪状态
                micBtn.innerHTML = `<i class="fas fa-microphone"></i> GMIC ${micIndex + 1} Ready`;
              } catch (error) {
                console.error('处理录音数据时出错:', error);
                // 即使处理失败，也要确保UI恢复正常
                micBtn.innerHTML = `<i class="fas fa-microphone"></i> GMIC ${micIndex + 1} Ready`;
              }
            } else {
              // 即使没有足够数据处理，也要确保UI恢复正常
              micBtn.innerHTML = `<i class="fas fa-microphone"></i> GMIC ${micIndex + 1} Ready`;
            }

            // 结束当前录音会话
            isNewRecordingSession = false;
            recordingSessionId = null;
            buttonTriggeredStop = false;  // 重置标志
          } catch (error) {
            console.error('发送停止录音命令失败:', error);
            buttonTriggeredStop = false;  // 确保重置标志
          }
        }
      }
    }

    // 初始化
    updateStatusUI();

    // 启动Azure语音识别
    function startBLEAzureRecognition() {
      // 如果已经有识别器，先停止
      if (bleRecognizer) {
        try {
          bleRecognizer.stopContinuousRecognitionAsync();
        } catch (e) {
          console.warn("停止旧识别器时出错:", e);
        }
      }

      // 初始化新的识别器
      if (!bleRecognizer) {
        bleRecognizer = initBLERecognizer();
        if (!bleRecognizer) {
          console.error("无法初始化Azure语音识别器!");
          return;
        }
      }

      // 添加一个延迟启动，确保连接有时间建立
      setTimeout(() => {
        try {
          // 启动连续识别
          console.log("启动语音识别...");

          // 添加启动超时保护
          let startSuccess = false;
          const startTimeoutId = setTimeout(() => {
            if (!startSuccess) {
              console.error("启动语音识别超时，尝试重建识别器");

              // 清理旧的识别器
              try {
                if (bleRecognizer) {
                  bleRecognizer.stopContinuousRecognitionAsync();
                  bleRecognizer.close();
                  bleRecognizer = null;
                }
              } catch (e) {
                console.warn("清理超时识别器时出错:", e);
              }

              // 重新初始化并启动
              bleRecognizer = initBLERecognizer();
              if (bleRecognizer) {
                setTimeout(() => {
                  try {
                    bleRecognizer.startContinuousRecognitionAsync(
                      () => {
                        console.log("Azure识别器启动成功");
                      },
                      (err) => {
                        console.error("Azure识别器启动失败:", err);
                      }
                    );
                  } catch (e) {
                    console.error("重试启动识别器时出错:", e);
                  }
                }, 1000);
              }
            }
          }, 8000); // 8秒超时

          // 启动连续识别
          bleRecognizer.startContinuousRecognitionAsync(
            () => {
              console.log("Azure识别器启动成功");
              startSuccess = true;
              clearTimeout(startTimeoutId);
            },
            (err) => {
              console.error("Azure识别器启动失败:", err);
              clearTimeout(startTimeoutId);

              // 尝试重新初始化并重启
              setTimeout(() => {
                if (bleRecognizer) {
                  try {
                    bleRecognizer.close();
                  } catch (e) { }
                }

                bleRecognizer = initBLERecognizer();
                if (bleRecognizer) {
                  setTimeout(() => {
                    try {
                      bleRecognizer.startContinuousRecognitionAsync();
                    } catch (e) {
                      console.error("重启识别器失败:", e);
                    }
                  }, 1000);
                }
              }, 2000);
            }
          );
        } catch (error) {
          console.error("启动Azure语音识别时出错:", error);
        }
      }, 1000); // 1秒延迟启动
    }

    // 监控WebSocket连接的函数
    function monitorWebSocketConnections() {
      // 查找所有 "wss://" 开头的连接
      const wsConns = Object.keys(window).filter(key => {
        try {
          return window[key] &&
            typeof window[key] === 'object' &&
            window[key].url &&
            typeof window[key].url === 'string' &&
            window[key].url.startsWith('wss://');
        } catch (e) {
          return false;
        }
      }).map(key => window[key]);

      // 输出连接状态
      if (wsConns.length > 0) {
        console.log(`找到 ${wsConns.length} 个WebSocket连接:`);
        wsConns.forEach((ws, i) => {
          console.log(`WebSocket ${i + 1}: ${ws.url}, 状态: ${ws.readyState}`);

          // 添加连接异常处理
          if (ws.readyState === WebSocket.CLOSING || ws.readyState === WebSocket.CLOSED) {
            console.warn(`WebSocket连接 ${i + 1} 已关闭或正在关闭`);
          }
        });
      } else {
        console.log("未找到活跃的WebSocket连接");
      }
    }

    // 强制清理所有WebSocket连接
    function forceCleanupWebSockets() {
      // 使用Chrome DevTools Protocol关闭所有WebSocket
      if (typeof chrome !== 'undefined' && chrome.webrtc) {
        try {
          chrome.webrtc.getStats(null, stats => {
            const webSocketStats = stats.filter(s => s.type === 'websocket');
            if (webSocketStats.length > 0) {
              console.log(`尝试强制关闭 ${webSocketStats.length} 个WebSocket连接`);
            }
          });
        } catch (e) {
          console.warn("无法使用CDP清理WebSocket:", e);
        }
      }

      // 尝试关闭所有具有close方法的对象
      const wsConns = Object.keys(window).filter(key => {
        try {
          return window[key] &&
            typeof window[key] === 'object' &&
            window[key].close &&
            typeof window[key].close === 'function' &&
            window[key].url &&
            typeof window[key].url === 'string' &&
            window[key].url.startsWith('wss://');
        } catch (e) {
          return false;
        }
      }).map(key => window[key]);

      if (wsConns.length > 0) {
        console.log(`强制关闭 ${wsConns.length} 个WebSocket连接`);
        wsConns.forEach((ws, i) => {
          try {
            ws.close();
            console.log(`已强制关闭WebSocket ${i + 1}`);
          } catch (e) {
            console.warn(`强制关闭WebSocket ${i + 1} 失败:`, e);
          }
        });
      }
    }

    // 确保页面关闭时清理所有连接
    window.addEventListener('beforeunload', () => {
      forceCleanupWebSockets();

      if (bleRecognizer) {
        try {
          bleRecognizer.stopContinuousRecognitionAsync();
          bleRecognizer.close();
        } catch (e) { }
      }
    });

    // 添加时间戳格式化函数
    function getTimeStamp() {
      const now = new Date();
      const hours = String(now.getHours()).padStart(2, '0');
      const minutes = String(now.getMinutes()).padStart(2, '0');
      const seconds = String(now.getSeconds()).padStart(2, '0');
      return `[${hours}:${minutes}:${seconds}]`;
    }
  </script>
</body>

</html>